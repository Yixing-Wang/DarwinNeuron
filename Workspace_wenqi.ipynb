{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyx/miniconda3/envs/snn/lib/python3.12/site-packages/numpy/_core/getlimits.py:551: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from src.RandmanFunctions import read_randman10_dataset\n",
    "from src.Models import RandmanSNN\n",
    "from src.EvolutionAlgorithms.EvolutionStrategy import ESModel\n",
    "from src.EvolutionAlgorithms.PseudoPSO import PPSOModel, PPSOModelWithPooling\n",
    "from src.Training import train_loop_snn\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myixing\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wyx/darwin_neuron/wandb/run-20250614_213048-kujphd4t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/DarwinNeuron/ES-Randman10/runs/kujphd4t' target=\"_blank\">sanity_check</a></strong> to <a href='https://wandb.ai/DarwinNeuron/ES-Randman10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/DarwinNeuron/ES-Randman10' target=\"_blank\">https://wandb.ai/DarwinNeuron/ES-Randman10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/DarwinNeuron/ES-Randman10/runs/kujphd4t' target=\"_blank\">https://wandb.ai/DarwinNeuron/ES-Randman10/runs/kujphd4t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "batch 0, loss: 2.380389, accuracy: 10.9%\n",
      "Test Error: \n",
      "Accuracy: 9.4%, Avg loss: 2.374867 \n",
      "\n",
      "batch 1, loss: 2.382493, accuracy: 9.4%\n",
      "Test Error: \n",
      "Accuracy: 9.4%, Avg loss: 2.366478 \n",
      "\n",
      "batch 2, loss: 2.362677, accuracy: 7.4%\n",
      "Test Error: \n",
      "Accuracy: 8.6%, Avg loss: 2.361515 \n",
      "\n",
      "batch 3, loss: 2.353785, accuracy: 9.0%\n",
      "Test Error: \n",
      "Accuracy: 9.0%, Avg loss: 2.355470 \n",
      "\n",
      "batch 4, loss: 2.349546, accuracy: 7.0%\n",
      "Test Error: \n",
      "Accuracy: 8.2%, Avg loss: 2.348285 \n",
      "\n",
      "batch 5, loss: 2.330541, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 8.9%, Avg loss: 2.343625 \n",
      "\n",
      "batch 6, loss: 2.336818, accuracy: 8.6%\n",
      "Test Error: \n",
      "Accuracy: 9.2%, Avg loss: 2.339010 \n",
      "\n",
      "batch 7, loss: 2.333914, accuracy: 9.0%\n",
      "Test Error: \n",
      "Accuracy: 9.1%, Avg loss: 2.332818 \n",
      "\n",
      "batch 8, loss: 2.336750, accuracy: 9.8%\n",
      "Test Error: \n",
      "Accuracy: 9.0%, Avg loss: 2.330187 \n",
      "\n",
      "batch 9, loss: 2.331414, accuracy: 8.2%\n",
      "Test Error: \n",
      "Accuracy: 9.2%, Avg loss: 2.327248 \n",
      "\n",
      "batch 10, loss: 2.313446, accuracy: 10.5%\n",
      "Test Error: \n",
      "Accuracy: 9.2%, Avg loss: 2.324018 \n",
      "\n",
      "batch 11, loss: 2.318978, accuracy: 9.0%\n",
      "Test Error: \n",
      "Accuracy: 9.3%, Avg loss: 2.321868 \n",
      "\n",
      "batch 12, loss: 2.325633, accuracy: 9.0%\n",
      "Test Error: \n",
      "Accuracy: 9.9%, Avg loss: 2.320173 \n",
      "\n",
      "batch 13, loss: 2.319195, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 10.0%, Avg loss: 2.319622 \n",
      "\n",
      "batch 14, loss: 2.321359, accuracy: 8.6%\n",
      "Test Error: \n",
      "Accuracy: 10.5%, Avg loss: 2.318305 \n",
      "\n",
      "batch 15, loss: 2.302522, accuracy: 11.3%\n",
      "Test Error: \n",
      "Accuracy: 10.5%, Avg loss: 2.316228 \n",
      "\n",
      "batch 16, loss: 2.294265, accuracy: 18.4%\n",
      "Test Error: \n",
      "Accuracy: 10.2%, Avg loss: 2.315232 \n",
      "\n",
      "batch 17, loss: 2.306861, accuracy: 10.2%\n",
      "Test Error: \n",
      "Accuracy: 10.1%, Avg loss: 2.314545 \n",
      "\n",
      "batch 18, loss: 2.307514, accuracy: 10.2%\n",
      "Test Error: \n",
      "Accuracy: 10.2%, Avg loss: 2.313377 \n",
      "\n",
      "batch 19, loss: 2.314075, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 10.1%, Avg loss: 2.312222 \n",
      "\n",
      "batch 20, loss: 2.308091, accuracy: 13.7%\n",
      "Test Error: \n",
      "Accuracy: 10.3%, Avg loss: 2.311700 \n",
      "\n",
      "batch 21, loss: 2.305701, accuracy: 9.4%\n",
      "Test Error: \n",
      "Accuracy: 10.3%, Avg loss: 2.311886 \n",
      "\n",
      "batch 22, loss: 2.301343, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 10.4%, Avg loss: 2.310813 \n",
      "\n",
      "batch 23, loss: 2.303535, accuracy: 10.9%\n",
      "Test Error: \n",
      "Accuracy: 10.4%, Avg loss: 2.310286 \n",
      "\n",
      "batch 24, loss: 2.302126, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 10.6%, Avg loss: 2.309644 \n",
      "\n",
      "batch 25, loss: 2.311114, accuracy: 8.6%\n",
      "Test Error: \n",
      "Accuracy: 10.8%, Avg loss: 2.309158 \n",
      "\n",
      "batch 26, loss: 2.306210, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 10.9%, Avg loss: 2.308559 \n",
      "\n",
      "batch 27, loss: 2.302253, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 10.8%, Avg loss: 2.308872 \n",
      "\n",
      "batch 28, loss: 2.304015, accuracy: 11.3%\n",
      "Test Error: \n",
      "Accuracy: 11.2%, Avg loss: 2.308153 \n",
      "\n",
      "batch 29, loss: 2.299301, accuracy: 10.9%\n",
      "Test Error: \n",
      "Accuracy: 11.1%, Avg loss: 2.307819 \n",
      "\n",
      "batch 30, loss: 2.306605, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 11.1%, Avg loss: 2.307500 \n",
      "\n",
      "batch 31, loss: 2.296496, accuracy: 10.9%\n",
      "Test Error: \n",
      "Accuracy: 10.8%, Avg loss: 2.307537 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "batch 0, loss: 2.297004, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 11.0%, Avg loss: 2.307385 \n",
      "\n",
      "batch 1, loss: 2.305422, accuracy: 10.5%\n",
      "Test Error: \n",
      "Accuracy: 11.2%, Avg loss: 2.307307 \n",
      "\n",
      "batch 2, loss: 2.298418, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 11.3%, Avg loss: 2.306309 \n",
      "\n",
      "batch 3, loss: 2.305959, accuracy: 10.5%\n",
      "Test Error: \n",
      "Accuracy: 11.3%, Avg loss: 2.306511 \n",
      "\n",
      "batch 4, loss: 2.294044, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 11.2%, Avg loss: 2.306758 \n",
      "\n",
      "batch 5, loss: 2.296813, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 11.3%, Avg loss: 2.306402 \n",
      "\n",
      "batch 6, loss: 2.296869, accuracy: 10.9%\n",
      "Test Error: \n",
      "Accuracy: 11.4%, Avg loss: 2.305841 \n",
      "\n",
      "batch 7, loss: 2.298379, accuracy: 10.5%\n",
      "Test Error: \n",
      "Accuracy: 11.3%, Avg loss: 2.305762 \n",
      "\n",
      "batch 8, loss: 2.298039, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 11.2%, Avg loss: 2.305835 \n",
      "\n",
      "batch 9, loss: 2.308937, accuracy: 9.4%\n",
      "Test Error: \n",
      "Accuracy: 11.2%, Avg loss: 2.305510 \n",
      "\n",
      "batch 10, loss: 2.305916, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 11.2%, Avg loss: 2.305718 \n",
      "\n",
      "batch 11, loss: 2.297390, accuracy: 11.3%\n",
      "Test Error: \n",
      "Accuracy: 11.2%, Avg loss: 2.305406 \n",
      "\n",
      "batch 12, loss: 2.294156, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 11.2%, Avg loss: 2.305536 \n",
      "\n",
      "batch 13, loss: 2.304364, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 11.3%, Avg loss: 2.305084 \n",
      "\n",
      "batch 14, loss: 2.304269, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 11.5%, Avg loss: 2.304724 \n",
      "\n",
      "batch 15, loss: 2.300545, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 11.4%, Avg loss: 2.304454 \n",
      "\n",
      "batch 16, loss: 2.304538, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 11.5%, Avg loss: 2.304226 \n",
      "\n",
      "batch 17, loss: 2.299059, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 11.6%, Avg loss: 2.303998 \n",
      "\n",
      "batch 18, loss: 2.297265, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 11.6%, Avg loss: 2.303867 \n",
      "\n",
      "batch 19, loss: 2.302730, accuracy: 13.7%\n",
      "Test Error: \n",
      "Accuracy: 11.6%, Avg loss: 2.303833 \n",
      "\n",
      "batch 20, loss: 2.291510, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 11.7%, Avg loss: 2.303326 \n",
      "\n",
      "batch 21, loss: 2.303014, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 11.7%, Avg loss: 2.303007 \n",
      "\n",
      "batch 22, loss: 2.297729, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 11.7%, Avg loss: 2.303269 \n",
      "\n",
      "batch 23, loss: 2.299277, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 11.7%, Avg loss: 2.303098 \n",
      "\n",
      "batch 24, loss: 2.299386, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 11.7%, Avg loss: 2.303127 \n",
      "\n",
      "batch 25, loss: 2.301995, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.303070 \n",
      "\n",
      "batch 26, loss: 2.305862, accuracy: 7.0%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.302887 \n",
      "\n",
      "batch 27, loss: 2.304065, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.302716 \n",
      "\n",
      "batch 28, loss: 2.297729, accuracy: 13.7%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.302450 \n",
      "\n",
      "batch 29, loss: 2.299758, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.302533 \n",
      "\n",
      "batch 30, loss: 2.294650, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.302348 \n",
      "\n",
      "batch 31, loss: 2.294657, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.302130 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "batch 0, loss: 2.287524, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.302027 \n",
      "\n",
      "batch 1, loss: 2.299550, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.302006 \n",
      "\n",
      "batch 2, loss: 2.298601, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.301824 \n",
      "\n",
      "batch 3, loss: 2.301016, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.301495 \n",
      "\n",
      "batch 4, loss: 2.295399, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.301331 \n",
      "\n",
      "batch 5, loss: 2.300275, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 11.9%, Avg loss: 2.301342 \n",
      "\n",
      "batch 6, loss: 2.292814, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.301470 \n",
      "\n",
      "batch 7, loss: 2.290645, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.301572 \n",
      "\n",
      "batch 8, loss: 2.304232, accuracy: 10.2%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.301456 \n",
      "\n",
      "batch 9, loss: 2.300542, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 11.8%, Avg loss: 2.301332 \n",
      "\n",
      "batch 10, loss: 2.304864, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 12.0%, Avg loss: 2.300990 \n",
      "\n",
      "batch 11, loss: 2.300456, accuracy: 11.3%\n",
      "Test Error: \n",
      "Accuracy: 12.1%, Avg loss: 2.300800 \n",
      "\n",
      "batch 12, loss: 2.303279, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 12.1%, Avg loss: 2.300711 \n",
      "\n",
      "batch 13, loss: 2.301229, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 11.9%, Avg loss: 2.300895 \n",
      "\n",
      "batch 14, loss: 2.299431, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 11.9%, Avg loss: 2.300814 \n",
      "\n",
      "batch 15, loss: 2.288358, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 12.0%, Avg loss: 2.300466 \n",
      "\n",
      "batch 16, loss: 2.297770, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 12.0%, Avg loss: 2.300372 \n",
      "\n",
      "batch 17, loss: 2.300766, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 12.1%, Avg loss: 2.300226 \n",
      "\n",
      "batch 18, loss: 2.294137, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 12.1%, Avg loss: 2.300141 \n",
      "\n",
      "batch 19, loss: 2.300849, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.300007 \n",
      "\n",
      "batch 20, loss: 2.298474, accuracy: 13.7%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299869 \n",
      "\n",
      "batch 21, loss: 2.287350, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 12.1%, Avg loss: 2.299894 \n",
      "\n",
      "batch 22, loss: 2.301014, accuracy: 10.2%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299681 \n",
      "\n",
      "batch 23, loss: 2.296829, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299686 \n",
      "\n",
      "batch 24, loss: 2.294406, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299407 \n",
      "\n",
      "batch 25, loss: 2.294116, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299093 \n",
      "\n",
      "batch 26, loss: 2.287034, accuracy: 17.2%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299262 \n",
      "\n",
      "batch 27, loss: 2.302382, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299234 \n",
      "\n",
      "batch 28, loss: 2.310318, accuracy: 7.8%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299301 \n",
      "\n",
      "batch 29, loss: 2.300005, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299088 \n",
      "\n",
      "batch 30, loss: 2.303377, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299025 \n",
      "\n",
      "batch 31, loss: 2.297876, accuracy: 10.9%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.298863 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "batch 0, loss: 2.296477, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.298857 \n",
      "\n",
      "batch 1, loss: 2.301211, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.298818 \n",
      "\n",
      "batch 2, loss: 2.293199, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.299005 \n",
      "\n",
      "batch 3, loss: 2.304368, accuracy: 10.5%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.298887 \n",
      "\n",
      "batch 4, loss: 2.293857, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 12.2%, Avg loss: 2.298800 \n",
      "\n",
      "batch 5, loss: 2.295543, accuracy: 10.9%\n",
      "Test Error: \n",
      "Accuracy: 12.3%, Avg loss: 2.298344 \n",
      "\n",
      "batch 6, loss: 2.299192, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 12.4%, Avg loss: 2.298204 \n",
      "\n",
      "batch 7, loss: 2.295933, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 12.3%, Avg loss: 2.297892 \n",
      "\n",
      "batch 8, loss: 2.296442, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 12.3%, Avg loss: 2.297773 \n",
      "\n",
      "batch 9, loss: 2.297305, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 12.4%, Avg loss: 2.297500 \n",
      "\n",
      "batch 10, loss: 2.300813, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 12.4%, Avg loss: 2.297281 \n",
      "\n",
      "batch 11, loss: 2.291731, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 12.4%, Avg loss: 2.297222 \n",
      "\n",
      "batch 12, loss: 2.297069, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 12.5%, Avg loss: 2.297176 \n",
      "\n",
      "batch 13, loss: 2.286444, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 12.5%, Avg loss: 2.297332 \n",
      "\n",
      "batch 14, loss: 2.293349, accuracy: 13.7%\n",
      "Test Error: \n",
      "Accuracy: 12.6%, Avg loss: 2.297428 \n",
      "\n",
      "batch 15, loss: 2.302397, accuracy: 10.5%\n",
      "Test Error: \n",
      "Accuracy: 12.5%, Avg loss: 2.297632 \n",
      "\n",
      "batch 16, loss: 2.297750, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 12.3%, Avg loss: 2.297292 \n",
      "\n",
      "batch 17, loss: 2.296100, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 12.4%, Avg loss: 2.297116 \n",
      "\n",
      "batch 18, loss: 2.301567, accuracy: 11.3%\n",
      "Test Error: \n",
      "Accuracy: 12.5%, Avg loss: 2.296920 \n",
      "\n",
      "batch 19, loss: 2.292660, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 12.5%, Avg loss: 2.296980 \n",
      "\n",
      "batch 20, loss: 2.299914, accuracy: 11.3%\n",
      "Test Error: \n",
      "Accuracy: 12.5%, Avg loss: 2.296836 \n",
      "\n",
      "batch 21, loss: 2.291473, accuracy: 19.1%\n",
      "Test Error: \n",
      "Accuracy: 12.5%, Avg loss: 2.296877 \n",
      "\n",
      "batch 22, loss: 2.290847, accuracy: 11.3%\n",
      "Test Error: \n",
      "Accuracy: 12.5%, Avg loss: 2.296719 \n",
      "\n",
      "batch 23, loss: 2.286978, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 12.4%, Avg loss: 2.296818 \n",
      "\n",
      "batch 24, loss: 2.297781, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 12.6%, Avg loss: 2.296527 \n",
      "\n",
      "batch 25, loss: 2.296419, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 12.5%, Avg loss: 2.296660 \n",
      "\n",
      "batch 26, loss: 2.295358, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 12.4%, Avg loss: 2.296382 \n",
      "\n",
      "batch 27, loss: 2.292213, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 12.3%, Avg loss: 2.296393 \n",
      "\n",
      "batch 28, loss: 2.286476, accuracy: 17.6%\n",
      "Test Error: \n",
      "Accuracy: 12.4%, Avg loss: 2.296231 \n",
      "\n",
      "batch 29, loss: 2.291157, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 12.7%, Avg loss: 2.295490 \n",
      "\n",
      "batch 30, loss: 2.295428, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 12.7%, Avg loss: 2.295536 \n",
      "\n",
      "batch 31, loss: 2.307144, accuracy: 7.8%\n",
      "Test Error: \n",
      "Accuracy: 12.8%, Avg loss: 2.295093 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "batch 0, loss: 2.298672, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 13.0%, Avg loss: 2.294892 \n",
      "\n",
      "batch 1, loss: 2.298001, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 13.1%, Avg loss: 2.294437 \n",
      "\n",
      "batch 2, loss: 2.297649, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 13.1%, Avg loss: 2.294127 \n",
      "\n",
      "batch 3, loss: 2.292973, accuracy: 13.3%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.293745 \n",
      "\n",
      "batch 4, loss: 2.293669, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 13.4%, Avg loss: 2.293849 \n",
      "\n",
      "batch 5, loss: 2.287613, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.293238 \n",
      "\n",
      "batch 6, loss: 2.302689, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 13.4%, Avg loss: 2.293166 \n",
      "\n",
      "batch 7, loss: 2.286497, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 13.4%, Avg loss: 2.292762 \n",
      "\n",
      "batch 8, loss: 2.291196, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 13.4%, Avg loss: 2.293008 \n",
      "\n",
      "batch 9, loss: 2.300870, accuracy: 8.6%\n",
      "Test Error: \n",
      "Accuracy: 13.4%, Avg loss: 2.292932 \n",
      "\n",
      "batch 10, loss: 2.290749, accuracy: 9.4%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.293206 \n",
      "\n",
      "batch 11, loss: 2.293666, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.293118 \n",
      "\n",
      "batch 12, loss: 2.297470, accuracy: 10.9%\n",
      "Test Error: \n",
      "Accuracy: 13.3%, Avg loss: 2.292960 \n",
      "\n",
      "batch 13, loss: 2.292020, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 13.3%, Avg loss: 2.292874 \n",
      "\n",
      "batch 14, loss: 2.298402, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.292448 \n",
      "\n",
      "batch 15, loss: 2.283306, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 13.0%, Avg loss: 2.292513 \n",
      "\n",
      "batch 16, loss: 2.293246, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.291787 \n",
      "\n",
      "batch 17, loss: 2.289103, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.292076 \n",
      "\n",
      "batch 18, loss: 2.299451, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.291893 \n",
      "\n",
      "batch 19, loss: 2.287458, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.291342 \n",
      "\n",
      "batch 20, loss: 2.277505, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 13.2%, Avg loss: 2.291221 \n",
      "\n",
      "batch 21, loss: 2.282857, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 13.4%, Avg loss: 2.291059 \n",
      "\n",
      "batch 22, loss: 2.292984, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 13.4%, Avg loss: 2.291121 \n",
      "\n",
      "batch 23, loss: 2.282279, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 13.4%, Avg loss: 2.290931 \n",
      "\n",
      "batch 24, loss: 2.289905, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 13.4%, Avg loss: 2.290143 \n",
      "\n",
      "batch 25, loss: 2.277525, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 13.6%, Avg loss: 2.289491 \n",
      "\n",
      "batch 26, loss: 2.279866, accuracy: 17.2%\n",
      "Test Error: \n",
      "Accuracy: 13.6%, Avg loss: 2.289195 \n",
      "\n",
      "batch 27, loss: 2.285739, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 13.6%, Avg loss: 2.288820 \n",
      "\n",
      "batch 28, loss: 2.303515, accuracy: 10.9%\n",
      "Test Error: \n",
      "Accuracy: 13.7%, Avg loss: 2.288287 \n",
      "\n",
      "batch 29, loss: 2.285735, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 13.9%, Avg loss: 2.287700 \n",
      "\n",
      "batch 30, loss: 2.270728, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 13.6%, Avg loss: 2.287807 \n",
      "\n",
      "batch 31, loss: 2.267108, accuracy: 18.8%\n",
      "Test Error: \n",
      "Accuracy: 13.7%, Avg loss: 2.288163 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "batch 0, loss: 2.296658, accuracy: 12.5%\n",
      "Test Error: \n",
      "Accuracy: 13.6%, Avg loss: 2.288203 \n",
      "\n",
      "batch 1, loss: 2.285374, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 13.6%, Avg loss: 2.288091 \n",
      "\n",
      "batch 2, loss: 2.268696, accuracy: 19.1%\n",
      "Test Error: \n",
      "Accuracy: 13.8%, Avg loss: 2.286956 \n",
      "\n",
      "batch 3, loss: 2.286037, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 13.8%, Avg loss: 2.286948 \n",
      "\n",
      "batch 4, loss: 2.285991, accuracy: 13.7%\n",
      "Test Error: \n",
      "Accuracy: 13.8%, Avg loss: 2.286500 \n",
      "\n",
      "batch 5, loss: 2.294109, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 13.9%, Avg loss: 2.286004 \n",
      "\n",
      "batch 6, loss: 2.281844, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 13.8%, Avg loss: 2.285812 \n",
      "\n",
      "batch 7, loss: 2.278809, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 13.9%, Avg loss: 2.285514 \n",
      "\n",
      "batch 8, loss: 2.289108, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 13.9%, Avg loss: 2.285028 \n",
      "\n",
      "batch 9, loss: 2.278424, accuracy: 17.6%\n",
      "Test Error: \n",
      "Accuracy: 14.0%, Avg loss: 2.284797 \n",
      "\n",
      "batch 10, loss: 2.287480, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 14.1%, Avg loss: 2.284461 \n",
      "\n",
      "batch 11, loss: 2.271521, accuracy: 18.8%\n",
      "Test Error: \n",
      "Accuracy: 14.1%, Avg loss: 2.283737 \n",
      "\n",
      "batch 12, loss: 2.267745, accuracy: 18.8%\n",
      "Test Error: \n",
      "Accuracy: 14.1%, Avg loss: 2.283176 \n",
      "\n",
      "batch 13, loss: 2.290396, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 14.2%, Avg loss: 2.281629 \n",
      "\n",
      "batch 14, loss: 2.265893, accuracy: 16.8%\n",
      "Test Error: \n",
      "Accuracy: 14.5%, Avg loss: 2.280326 \n",
      "\n",
      "batch 15, loss: 2.274504, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 14.6%, Avg loss: 2.279939 \n",
      "\n",
      "batch 16, loss: 2.273786, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 14.5%, Avg loss: 2.279400 \n",
      "\n",
      "batch 17, loss: 2.288007, accuracy: 12.9%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.278578 \n",
      "\n",
      "batch 18, loss: 2.253636, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.278744 \n",
      "\n",
      "batch 19, loss: 2.256240, accuracy: 17.6%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.278326 \n",
      "\n",
      "batch 20, loss: 2.267006, accuracy: 19.1%\n",
      "Test Error: \n",
      "Accuracy: 15.0%, Avg loss: 2.277204 \n",
      "\n",
      "batch 21, loss: 2.285977, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 15.2%, Avg loss: 2.277011 \n",
      "\n",
      "batch 22, loss: 2.283979, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 15.2%, Avg loss: 2.276514 \n",
      "\n",
      "batch 23, loss: 2.284024, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 15.3%, Avg loss: 2.276559 \n",
      "\n",
      "batch 24, loss: 2.273064, accuracy: 13.7%\n",
      "Test Error: \n",
      "Accuracy: 15.2%, Avg loss: 2.276065 \n",
      "\n",
      "batch 25, loss: 2.265851, accuracy: 17.6%\n",
      "Test Error: \n",
      "Accuracy: 15.0%, Avg loss: 2.275983 \n",
      "\n",
      "batch 26, loss: 2.279898, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 14.9%, Avg loss: 2.276688 \n",
      "\n",
      "batch 27, loss: 2.289885, accuracy: 12.1%\n",
      "Test Error: \n",
      "Accuracy: 14.9%, Avg loss: 2.276694 \n",
      "\n",
      "batch 28, loss: 2.288595, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 15.0%, Avg loss: 2.276670 \n",
      "\n",
      "batch 29, loss: 2.291546, accuracy: 11.7%\n",
      "Test Error: \n",
      "Accuracy: 14.9%, Avg loss: 2.276327 \n",
      "\n",
      "batch 30, loss: 2.258606, accuracy: 20.3%\n",
      "Test Error: \n",
      "Accuracy: 15.0%, Avg loss: 2.275958 \n",
      "\n",
      "batch 31, loss: 2.286700, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 15.0%, Avg loss: 2.274932 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "batch 0, loss: 2.281365, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 14.9%, Avg loss: 2.274700 \n",
      "\n",
      "batch 1, loss: 2.270357, accuracy: 21.5%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.274782 \n",
      "\n",
      "batch 2, loss: 2.259610, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 14.6%, Avg loss: 2.274805 \n",
      "\n",
      "batch 3, loss: 2.266272, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.274548 \n",
      "\n",
      "batch 4, loss: 2.262759, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 14.6%, Avg loss: 2.274881 \n",
      "\n",
      "batch 5, loss: 2.278371, accuracy: 19.1%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.274014 \n",
      "\n",
      "batch 6, loss: 2.270735, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 14.6%, Avg loss: 2.274506 \n",
      "\n",
      "batch 7, loss: 2.283348, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 14.6%, Avg loss: 2.274835 \n",
      "\n",
      "batch 8, loss: 2.251122, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 14.9%, Avg loss: 2.273917 \n",
      "\n",
      "batch 9, loss: 2.276283, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.273961 \n",
      "\n",
      "batch 10, loss: 2.281776, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 14.7%, Avg loss: 2.275127 \n",
      "\n",
      "batch 11, loss: 2.266205, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 14.6%, Avg loss: 2.274505 \n",
      "\n",
      "batch 12, loss: 2.280651, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.274278 \n",
      "\n",
      "batch 13, loss: 2.273295, accuracy: 14.5%\n",
      "Test Error: \n",
      "Accuracy: 14.7%, Avg loss: 2.274572 \n",
      "\n",
      "batch 14, loss: 2.247188, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 14.5%, Avg loss: 2.274253 \n",
      "\n",
      "batch 15, loss: 2.274882, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.273813 \n",
      "\n",
      "batch 16, loss: 2.290701, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.274173 \n",
      "\n",
      "batch 17, loss: 2.259018, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 14.6%, Avg loss: 2.273649 \n",
      "\n",
      "batch 18, loss: 2.260104, accuracy: 21.5%\n",
      "Test Error: \n",
      "Accuracy: 14.7%, Avg loss: 2.272630 \n",
      "\n",
      "batch 19, loss: 2.266084, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 14.8%, Avg loss: 2.271914 \n",
      "\n",
      "batch 20, loss: 2.279495, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 15.1%, Avg loss: 2.271727 \n",
      "\n",
      "batch 21, loss: 2.254065, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 15.1%, Avg loss: 2.271555 \n",
      "\n",
      "batch 22, loss: 2.250482, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 15.2%, Avg loss: 2.270946 \n",
      "\n",
      "batch 23, loss: 2.246560, accuracy: 18.8%\n",
      "Test Error: \n",
      "Accuracy: 15.4%, Avg loss: 2.270546 \n",
      "\n",
      "batch 24, loss: 2.265485, accuracy: 18.4%\n",
      "Test Error: \n",
      "Accuracy: 15.4%, Avg loss: 2.270174 \n",
      "\n",
      "batch 25, loss: 2.272830, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 15.4%, Avg loss: 2.269258 \n",
      "\n",
      "batch 26, loss: 2.246881, accuracy: 21.5%\n",
      "Test Error: \n",
      "Accuracy: 15.3%, Avg loss: 2.270120 \n",
      "\n",
      "batch 27, loss: 2.263885, accuracy: 19.1%\n",
      "Test Error: \n",
      "Accuracy: 15.8%, Avg loss: 2.269415 \n",
      "\n",
      "batch 28, loss: 2.247273, accuracy: 20.7%\n",
      "Test Error: \n",
      "Accuracy: 15.6%, Avg loss: 2.269512 \n",
      "\n",
      "batch 29, loss: 2.277560, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 15.6%, Avg loss: 2.269057 \n",
      "\n",
      "batch 30, loss: 2.268872, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 15.8%, Avg loss: 2.268233 \n",
      "\n",
      "batch 31, loss: 2.265270, accuracy: 23.4%\n",
      "Test Error: \n",
      "Accuracy: 15.8%, Avg loss: 2.267718 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "batch 0, loss: 2.239766, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 15.6%, Avg loss: 2.267386 \n",
      "\n",
      "batch 1, loss: 2.252450, accuracy: 18.4%\n",
      "Test Error: \n",
      "Accuracy: 15.7%, Avg loss: 2.267873 \n",
      "\n",
      "batch 2, loss: 2.256258, accuracy: 18.8%\n",
      "Test Error: \n",
      "Accuracy: 15.8%, Avg loss: 2.267810 \n",
      "\n",
      "batch 3, loss: 2.225918, accuracy: 24.6%\n",
      "Test Error: \n",
      "Accuracy: 15.8%, Avg loss: 2.267830 \n",
      "\n",
      "batch 4, loss: 2.266365, accuracy: 17.2%\n",
      "Test Error: \n",
      "Accuracy: 16.0%, Avg loss: 2.267569 \n",
      "\n",
      "batch 5, loss: 2.233450, accuracy: 20.3%\n",
      "Test Error: \n",
      "Accuracy: 16.2%, Avg loss: 2.267346 \n",
      "\n",
      "batch 6, loss: 2.264180, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 16.4%, Avg loss: 2.266797 \n",
      "\n",
      "batch 7, loss: 2.256139, accuracy: 16.8%\n",
      "Test Error: \n",
      "Accuracy: 16.8%, Avg loss: 2.265766 \n",
      "\n",
      "batch 8, loss: 2.270289, accuracy: 18.4%\n",
      "Test Error: \n",
      "Accuracy: 16.8%, Avg loss: 2.265104 \n",
      "\n",
      "batch 9, loss: 2.252211, accuracy: 18.4%\n",
      "Test Error: \n",
      "Accuracy: 16.8%, Avg loss: 2.264539 \n",
      "\n",
      "batch 10, loss: 2.269454, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 16.7%, Avg loss: 2.263784 \n",
      "\n",
      "batch 11, loss: 2.253554, accuracy: 17.2%\n",
      "Test Error: \n",
      "Accuracy: 16.8%, Avg loss: 2.264120 \n",
      "\n",
      "batch 12, loss: 2.248094, accuracy: 20.3%\n",
      "Test Error: \n",
      "Accuracy: 17.2%, Avg loss: 2.262266 \n",
      "\n",
      "batch 13, loss: 2.282787, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 17.2%, Avg loss: 2.263711 \n",
      "\n",
      "batch 14, loss: 2.281757, accuracy: 13.7%\n",
      "Test Error: \n",
      "Accuracy: 17.5%, Avg loss: 2.261671 \n",
      "\n",
      "batch 15, loss: 2.270680, accuracy: 17.2%\n",
      "Test Error: \n",
      "Accuracy: 17.8%, Avg loss: 2.261126 \n",
      "\n",
      "batch 16, loss: 2.268522, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 17.5%, Avg loss: 2.261751 \n",
      "\n",
      "batch 17, loss: 2.265829, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 17.6%, Avg loss: 2.261382 \n",
      "\n",
      "batch 18, loss: 2.249257, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 18.4%, Avg loss: 2.261152 \n",
      "\n",
      "batch 19, loss: 2.223525, accuracy: 28.1%\n",
      "Test Error: \n",
      "Accuracy: 18.4%, Avg loss: 2.261256 \n",
      "\n",
      "batch 20, loss: 2.231159, accuracy: 22.7%\n",
      "Test Error: \n",
      "Accuracy: 18.1%, Avg loss: 2.261883 \n",
      "\n",
      "batch 21, loss: 2.282951, accuracy: 20.3%\n",
      "Test Error: \n",
      "Accuracy: 18.1%, Avg loss: 2.261453 \n",
      "\n",
      "batch 22, loss: 2.277911, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 18.3%, Avg loss: 2.260721 \n",
      "\n",
      "batch 23, loss: 2.249937, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 18.2%, Avg loss: 2.260704 \n",
      "\n",
      "batch 24, loss: 2.275046, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 17.4%, Avg loss: 2.260453 \n",
      "\n",
      "batch 25, loss: 2.267066, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 17.3%, Avg loss: 2.258762 \n",
      "\n",
      "batch 26, loss: 2.242304, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 17.5%, Avg loss: 2.258301 \n",
      "\n",
      "batch 27, loss: 2.278042, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 17.4%, Avg loss: 2.257918 \n",
      "\n",
      "batch 28, loss: 2.243371, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 17.3%, Avg loss: 2.257635 \n",
      "\n",
      "batch 29, loss: 2.215654, accuracy: 22.3%\n",
      "Test Error: \n",
      "Accuracy: 17.5%, Avg loss: 2.256952 \n",
      "\n",
      "batch 30, loss: 2.267929, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 17.3%, Avg loss: 2.257390 \n",
      "\n",
      "batch 31, loss: 2.265132, accuracy: 17.2%\n",
      "Test Error: \n",
      "Accuracy: 17.3%, Avg loss: 2.257266 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "batch 0, loss: 2.243472, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 17.3%, Avg loss: 2.256358 \n",
      "\n",
      "batch 1, loss: 2.231801, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 17.3%, Avg loss: 2.254881 \n",
      "\n",
      "batch 2, loss: 2.247040, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 17.5%, Avg loss: 2.254768 \n",
      "\n",
      "batch 3, loss: 2.244766, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 17.3%, Avg loss: 2.253748 \n",
      "\n",
      "batch 4, loss: 2.234853, accuracy: 21.5%\n",
      "Test Error: \n",
      "Accuracy: 17.2%, Avg loss: 2.253124 \n",
      "\n",
      "batch 5, loss: 2.252576, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 17.5%, Avg loss: 2.252260 \n",
      "\n",
      "batch 6, loss: 2.241222, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 17.5%, Avg loss: 2.252408 \n",
      "\n",
      "batch 7, loss: 2.229044, accuracy: 21.9%\n",
      "Test Error: \n",
      "Accuracy: 17.6%, Avg loss: 2.251158 \n",
      "\n",
      "batch 8, loss: 2.252872, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 17.6%, Avg loss: 2.249868 \n",
      "\n",
      "batch 9, loss: 2.267037, accuracy: 15.2%\n",
      "Test Error: \n",
      "Accuracy: 17.8%, Avg loss: 2.247809 \n",
      "\n",
      "batch 10, loss: 2.210773, accuracy: 24.6%\n",
      "Test Error: \n",
      "Accuracy: 17.8%, Avg loss: 2.245646 \n",
      "\n",
      "batch 11, loss: 2.265842, accuracy: 16.0%\n",
      "Test Error: \n",
      "Accuracy: 17.8%, Avg loss: 2.245600 \n",
      "\n",
      "batch 12, loss: 2.220896, accuracy: 21.9%\n",
      "Test Error: \n",
      "Accuracy: 17.8%, Avg loss: 2.245780 \n",
      "\n",
      "batch 13, loss: 2.238671, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 18.0%, Avg loss: 2.244601 \n",
      "\n",
      "batch 14, loss: 2.232188, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 17.8%, Avg loss: 2.243758 \n",
      "\n",
      "batch 15, loss: 2.271795, accuracy: 14.1%\n",
      "Test Error: \n",
      "Accuracy: 17.9%, Avg loss: 2.242039 \n",
      "\n",
      "batch 16, loss: 2.233064, accuracy: 20.3%\n",
      "Test Error: \n",
      "Accuracy: 18.1%, Avg loss: 2.240488 \n",
      "\n",
      "batch 17, loss: 2.212155, accuracy: 23.0%\n",
      "Test Error: \n",
      "Accuracy: 18.4%, Avg loss: 2.239086 \n",
      "\n",
      "batch 18, loss: 2.219632, accuracy: 18.4%\n",
      "Test Error: \n",
      "Accuracy: 18.6%, Avg loss: 2.238152 \n",
      "\n",
      "batch 19, loss: 2.245473, accuracy: 18.4%\n",
      "Test Error: \n",
      "Accuracy: 18.0%, Avg loss: 2.239388 \n",
      "\n",
      "batch 20, loss: 2.216503, accuracy: 18.8%\n",
      "Test Error: \n",
      "Accuracy: 17.8%, Avg loss: 2.238441 \n",
      "\n",
      "batch 21, loss: 2.232228, accuracy: 16.8%\n",
      "Test Error: \n",
      "Accuracy: 17.7%, Avg loss: 2.237399 \n",
      "\n",
      "batch 22, loss: 2.268871, accuracy: 14.8%\n",
      "Test Error: \n",
      "Accuracy: 17.8%, Avg loss: 2.236172 \n",
      "\n",
      "batch 23, loss: 2.213427, accuracy: 20.7%\n",
      "Test Error: \n",
      "Accuracy: 18.2%, Avg loss: 2.235875 \n",
      "\n",
      "batch 24, loss: 2.237278, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 18.3%, Avg loss: 2.234376 \n",
      "\n",
      "batch 25, loss: 2.214420, accuracy: 19.1%\n",
      "Test Error: \n",
      "Accuracy: 18.9%, Avg loss: 2.231852 \n",
      "\n",
      "batch 26, loss: 2.224434, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 19.0%, Avg loss: 2.232867 \n",
      "\n",
      "batch 27, loss: 2.226445, accuracy: 20.7%\n",
      "Test Error: \n",
      "Accuracy: 20.0%, Avg loss: 2.231146 \n",
      "\n",
      "batch 28, loss: 2.231620, accuracy: 19.1%\n",
      "Test Error: \n",
      "Accuracy: 20.1%, Avg loss: 2.231428 \n",
      "\n",
      "batch 29, loss: 2.232328, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 20.1%, Avg loss: 2.231642 \n",
      "\n",
      "batch 30, loss: 2.238580, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 20.2%, Avg loss: 2.230264 \n",
      "\n",
      "batch 31, loss: 2.217188, accuracy: 18.8%\n",
      "Test Error: \n",
      "Accuracy: 20.1%, Avg loss: 2.230303 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "batch 0, loss: 2.217301, accuracy: 22.3%\n",
      "Test Error: \n",
      "Accuracy: 20.1%, Avg loss: 2.229644 \n",
      "\n",
      "batch 1, loss: 2.248896, accuracy: 16.4%\n",
      "Test Error: \n",
      "Accuracy: 19.7%, Avg loss: 2.229840 \n",
      "\n",
      "batch 2, loss: 2.241719, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 19.5%, Avg loss: 2.229641 \n",
      "\n",
      "batch 3, loss: 2.240880, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 19.8%, Avg loss: 2.228706 \n",
      "\n",
      "batch 4, loss: 2.240300, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 19.8%, Avg loss: 2.228146 \n",
      "\n",
      "batch 5, loss: 2.211790, accuracy: 21.5%\n",
      "Test Error: \n",
      "Accuracy: 19.8%, Avg loss: 2.228168 \n",
      "\n",
      "batch 6, loss: 2.214545, accuracy: 22.7%\n",
      "Test Error: \n",
      "Accuracy: 19.6%, Avg loss: 2.227826 \n",
      "\n",
      "batch 7, loss: 2.167439, accuracy: 27.7%\n",
      "Test Error: \n",
      "Accuracy: 19.6%, Avg loss: 2.227545 \n",
      "\n",
      "batch 8, loss: 2.235695, accuracy: 18.4%\n",
      "Test Error: \n",
      "Accuracy: 19.3%, Avg loss: 2.227844 \n",
      "\n",
      "batch 9, loss: 2.214431, accuracy: 20.3%\n",
      "Test Error: \n",
      "Accuracy: 19.3%, Avg loss: 2.226545 \n",
      "\n",
      "batch 10, loss: 2.220655, accuracy: 21.9%\n",
      "Test Error: \n",
      "Accuracy: 19.4%, Avg loss: 2.223898 \n",
      "\n",
      "batch 11, loss: 2.240025, accuracy: 19.1%\n",
      "Test Error: \n",
      "Accuracy: 19.0%, Avg loss: 2.224281 \n",
      "\n",
      "batch 12, loss: 2.215272, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 18.9%, Avg loss: 2.222877 \n",
      "\n",
      "batch 13, loss: 2.210361, accuracy: 21.9%\n",
      "Test Error: \n",
      "Accuracy: 18.8%, Avg loss: 2.222158 \n",
      "\n",
      "batch 14, loss: 2.209680, accuracy: 21.5%\n",
      "Test Error: \n",
      "Accuracy: 19.0%, Avg loss: 2.218992 \n",
      "\n",
      "batch 15, loss: 2.195799, accuracy: 21.5%\n",
      "Test Error: \n",
      "Accuracy: 19.5%, Avg loss: 2.215494 \n",
      "\n",
      "batch 16, loss: 2.154130, accuracy: 25.4%\n",
      "Test Error: \n",
      "Accuracy: 19.4%, Avg loss: 2.212007 \n",
      "\n",
      "batch 17, loss: 2.238615, accuracy: 17.2%\n",
      "Test Error: \n",
      "Accuracy: 19.4%, Avg loss: 2.211684 \n",
      "\n",
      "batch 18, loss: 2.211588, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 19.2%, Avg loss: 2.209884 \n",
      "\n",
      "batch 19, loss: 2.207325, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 18.8%, Avg loss: 2.209411 \n",
      "\n",
      "batch 20, loss: 2.156086, accuracy: 22.3%\n",
      "Test Error: \n",
      "Accuracy: 18.4%, Avg loss: 2.208316 \n",
      "\n",
      "batch 21, loss: 2.217360, accuracy: 18.8%\n",
      "Test Error: \n",
      "Accuracy: 18.8%, Avg loss: 2.207016 \n",
      "\n",
      "batch 22, loss: 2.218450, accuracy: 18.0%\n",
      "Test Error: \n",
      "Accuracy: 18.2%, Avg loss: 2.208117 \n",
      "\n",
      "batch 23, loss: 2.206607, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 18.8%, Avg loss: 2.204535 \n",
      "\n",
      "batch 24, loss: 2.205412, accuracy: 20.7%\n",
      "Test Error: \n",
      "Accuracy: 18.7%, Avg loss: 2.202242 \n",
      "\n",
      "batch 25, loss: 2.185294, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 19.1%, Avg loss: 2.198851 \n",
      "\n",
      "batch 26, loss: 2.197330, accuracy: 21.9%\n",
      "Test Error: \n",
      "Accuracy: 19.4%, Avg loss: 2.198837 \n",
      "\n",
      "batch 27, loss: 2.201529, accuracy: 21.5%\n",
      "Test Error: \n",
      "Accuracy: 19.2%, Avg loss: 2.198183 \n",
      "\n",
      "batch 28, loss: 2.153534, accuracy: 25.0%\n",
      "Test Error: \n",
      "Accuracy: 20.1%, Avg loss: 2.194006 \n",
      "\n",
      "batch 29, loss: 2.191294, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 19.8%, Avg loss: 2.195542 \n",
      "\n",
      "batch 30, loss: 2.217971, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 19.9%, Avg loss: 2.193197 \n",
      "\n",
      "batch 31, loss: 2.215837, accuracy: 21.9%\n",
      "Test Error: \n",
      "Accuracy: 19.6%, Avg loss: 2.194434 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "batch 0, loss: 2.171282, accuracy: 24.2%\n",
      "Test Error: \n",
      "Accuracy: 19.4%, Avg loss: 2.194493 \n",
      "\n",
      "batch 1, loss: 2.176358, accuracy: 21.5%\n",
      "Test Error: \n",
      "Accuracy: 19.5%, Avg loss: 2.194421 \n",
      "\n",
      "batch 2, loss: 2.169259, accuracy: 24.6%\n",
      "Test Error: \n",
      "Accuracy: 20.2%, Avg loss: 2.191949 \n",
      "\n",
      "batch 3, loss: 2.193324, accuracy: 20.3%\n",
      "Test Error: \n",
      "Accuracy: 20.9%, Avg loss: 2.189706 \n",
      "\n",
      "batch 4, loss: 2.167912, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 20.8%, Avg loss: 2.186777 \n",
      "\n",
      "batch 5, loss: 2.155207, accuracy: 23.0%\n",
      "Test Error: \n",
      "Accuracy: 20.6%, Avg loss: 2.185808 \n",
      "\n",
      "batch 6, loss: 2.166598, accuracy: 25.4%\n",
      "Test Error: \n",
      "Accuracy: 21.0%, Avg loss: 2.183157 \n",
      "\n",
      "batch 7, loss: 2.172047, accuracy: 25.4%\n",
      "Test Error: \n",
      "Accuracy: 21.1%, Avg loss: 2.181758 \n",
      "\n",
      "batch 8, loss: 2.192226, accuracy: 22.7%\n",
      "Test Error: \n",
      "Accuracy: 20.9%, Avg loss: 2.180149 \n",
      "\n",
      "batch 9, loss: 2.180722, accuracy: 23.4%\n",
      "Test Error: \n",
      "Accuracy: 21.1%, Avg loss: 2.175305 \n",
      "\n",
      "batch 10, loss: 2.196193, accuracy: 20.7%\n",
      "Test Error: \n",
      "Accuracy: 21.2%, Avg loss: 2.174189 \n",
      "\n",
      "batch 11, loss: 2.130113, accuracy: 25.8%\n",
      "Test Error: \n",
      "Accuracy: 21.2%, Avg loss: 2.175944 \n",
      "\n",
      "batch 12, loss: 2.161470, accuracy: 25.0%\n",
      "Test Error: \n",
      "Accuracy: 21.4%, Avg loss: 2.177471 \n",
      "\n",
      "batch 13, loss: 2.132588, accuracy: 24.6%\n",
      "Test Error: \n",
      "Accuracy: 21.4%, Avg loss: 2.177270 \n",
      "\n",
      "batch 14, loss: 2.116955, accuracy: 23.4%\n",
      "Test Error: \n",
      "Accuracy: 21.5%, Avg loss: 2.174724 \n",
      "\n",
      "batch 15, loss: 2.227393, accuracy: 15.6%\n",
      "Test Error: \n",
      "Accuracy: 22.3%, Avg loss: 2.172967 \n",
      "\n",
      "batch 16, loss: 2.172304, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 22.8%, Avg loss: 2.171183 \n",
      "\n",
      "batch 17, loss: 2.193326, accuracy: 17.6%\n",
      "Test Error: \n",
      "Accuracy: 23.2%, Avg loss: 2.167609 \n",
      "\n",
      "batch 18, loss: 2.205702, accuracy: 19.9%\n",
      "Test Error: \n",
      "Accuracy: 22.9%, Avg loss: 2.167266 \n",
      "\n",
      "batch 19, loss: 2.177580, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 22.9%, Avg loss: 2.163758 \n",
      "\n",
      "batch 20, loss: 2.182274, accuracy: 19.5%\n",
      "Test Error: \n",
      "Accuracy: 23.2%, Avg loss: 2.162015 \n",
      "\n",
      "batch 21, loss: 2.164895, accuracy: 23.0%\n",
      "Test Error: \n",
      "Accuracy: 23.4%, Avg loss: 2.161004 \n",
      "\n",
      "batch 22, loss: 2.155873, accuracy: 23.0%\n",
      "Test Error: \n",
      "Accuracy: 23.4%, Avg loss: 2.158918 \n",
      "\n",
      "batch 23, loss: 2.191959, accuracy: 18.4%\n",
      "Test Error: \n",
      "Accuracy: 23.5%, Avg loss: 2.157696 \n",
      "\n",
      "batch 24, loss: 2.177742, accuracy: 20.7%\n",
      "Test Error: \n",
      "Accuracy: 23.6%, Avg loss: 2.154740 \n",
      "\n",
      "batch 25, loss: 2.139873, accuracy: 23.8%\n",
      "Test Error: \n",
      "Accuracy: 23.5%, Avg loss: 2.154368 \n",
      "\n",
      "batch 26, loss: 2.176805, accuracy: 21.1%\n",
      "Test Error: \n",
      "Accuracy: 23.5%, Avg loss: 2.153361 \n",
      "\n",
      "batch 27, loss: 2.114488, accuracy: 28.9%\n",
      "Test Error: \n",
      "Accuracy: 23.4%, Avg loss: 2.150087 \n",
      "\n",
      "batch 28, loss: 2.127017, accuracy: 26.6%\n",
      "Test Error: \n",
      "Accuracy: 23.8%, Avg loss: 2.146881 \n",
      "\n",
      "batch 29, loss: 2.136643, accuracy: 23.0%\n",
      "Test Error: \n",
      "Accuracy: 24.1%, Avg loss: 2.144831 \n",
      "\n",
      "batch 30, loss: 2.143718, accuracy: 22.3%\n",
      "Test Error: \n",
      "Accuracy: 24.6%, Avg loss: 2.138260 \n",
      "\n",
      "batch 31, loss: 2.127586, accuracy: 28.1%\n",
      "Test Error: \n",
      "Accuracy: 24.4%, Avg loss: 2.136202 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "batch 0, loss: 2.147635, accuracy: 23.8%\n",
      "Test Error: \n",
      "Accuracy: 24.3%, Avg loss: 2.133624 \n",
      "\n",
      "batch 1, loss: 2.126679, accuracy: 25.0%\n",
      "Test Error: \n",
      "Accuracy: 23.9%, Avg loss: 2.130382 \n",
      "\n",
      "batch 2, loss: 2.151680, accuracy: 23.0%\n",
      "Test Error: \n",
      "Accuracy: 24.4%, Avg loss: 2.125251 \n",
      "\n",
      "batch 3, loss: 2.161389, accuracy: 23.0%\n",
      "Test Error: \n",
      "Accuracy: 24.3%, Avg loss: 2.120405 \n",
      "\n",
      "batch 4, loss: 2.116136, accuracy: 26.6%\n",
      "Test Error: \n",
      "Accuracy: 24.8%, Avg loss: 2.114309 \n",
      "\n",
      "batch 5, loss: 2.101666, accuracy: 26.6%\n",
      "Test Error: \n",
      "Accuracy: 25.4%, Avg loss: 2.109721 \n",
      "\n",
      "batch 6, loss: 2.114079, accuracy: 26.6%\n",
      "Test Error: \n",
      "Accuracy: 26.3%, Avg loss: 2.101596 \n",
      "\n",
      "batch 7, loss: 2.107021, accuracy: 28.1%\n",
      "Test Error: \n",
      "Accuracy: 26.7%, Avg loss: 2.094384 \n",
      "\n",
      "batch 8, loss: 2.128560, accuracy: 25.0%\n",
      "Test Error: \n",
      "Accuracy: 26.7%, Avg loss: 2.086010 \n",
      "\n",
      "batch 9, loss: 2.119745, accuracy: 24.2%\n",
      "Test Error: \n",
      "Accuracy: 27.1%, Avg loss: 2.081091 \n",
      "\n",
      "batch 10, loss: 2.050323, accuracy: 28.9%\n",
      "Test Error: \n",
      "Accuracy: 27.2%, Avg loss: 2.079005 \n",
      "\n",
      "batch 11, loss: 2.075995, accuracy: 28.1%\n",
      "Test Error: \n",
      "Accuracy: 26.5%, Avg loss: 2.077461 \n",
      "\n",
      "batch 12, loss: 2.121628, accuracy: 23.8%\n",
      "Test Error: \n",
      "Accuracy: 26.7%, Avg loss: 2.073484 \n",
      "\n",
      "batch 13, loss: 2.063024, accuracy: 26.6%\n",
      "Test Error: \n",
      "Accuracy: 27.3%, Avg loss: 2.065898 \n",
      "\n",
      "batch 14, loss: 2.069872, accuracy: 28.5%\n",
      "Test Error: \n",
      "Accuracy: 27.9%, Avg loss: 2.060457 \n",
      "\n",
      "batch 15, loss: 2.077380, accuracy: 31.2%\n",
      "Test Error: \n",
      "Accuracy: 27.6%, Avg loss: 2.057065 \n",
      "\n",
      "batch 16, loss: 2.103701, accuracy: 25.0%\n",
      "Test Error: \n",
      "Accuracy: 27.7%, Avg loss: 2.053823 \n",
      "\n",
      "batch 17, loss: 2.074072, accuracy: 28.9%\n",
      "Test Error: \n",
      "Accuracy: 28.2%, Avg loss: 2.049209 \n",
      "\n",
      "batch 18, loss: 2.094897, accuracy: 25.4%\n",
      "Test Error: \n",
      "Accuracy: 28.1%, Avg loss: 2.047127 \n",
      "\n",
      "batch 19, loss: 2.041114, accuracy: 28.5%\n",
      "Test Error: \n",
      "Accuracy: 28.0%, Avg loss: 2.042878 \n",
      "\n",
      "batch 20, loss: 2.037539, accuracy: 28.9%\n",
      "Test Error: \n",
      "Accuracy: 28.4%, Avg loss: 2.039335 \n",
      "\n",
      "batch 21, loss: 2.102308, accuracy: 26.6%\n",
      "Test Error: \n",
      "Accuracy: 28.4%, Avg loss: 2.035122 \n",
      "\n",
      "batch 22, loss: 1.999094, accuracy: 29.7%\n",
      "Test Error: \n",
      "Accuracy: 28.6%, Avg loss: 2.033171 \n",
      "\n",
      "batch 23, loss: 2.077581, accuracy: 28.5%\n",
      "Test Error: \n",
      "Accuracy: 28.8%, Avg loss: 2.028404 \n",
      "\n",
      "batch 24, loss: 2.019894, accuracy: 32.8%\n",
      "Test Error: \n",
      "Accuracy: 29.1%, Avg loss: 2.023415 \n",
      "\n",
      "batch 25, loss: 2.053964, accuracy: 28.9%\n",
      "Test Error: \n",
      "Accuracy: 29.6%, Avg loss: 2.014714 \n",
      "\n",
      "batch 26, loss: 2.027580, accuracy: 29.3%\n",
      "Test Error: \n",
      "Accuracy: 30.2%, Avg loss: 2.007208 \n",
      "\n",
      "batch 27, loss: 1.971033, accuracy: 31.6%\n",
      "Test Error: \n",
      "Accuracy: 30.6%, Avg loss: 2.002549 \n",
      "\n",
      "batch 28, loss: 1.967736, accuracy: 31.6%\n",
      "Test Error: \n",
      "Accuracy: 30.9%, Avg loss: 1.996153 \n",
      "\n",
      "batch 29, loss: 2.014514, accuracy: 31.2%\n",
      "Test Error: \n",
      "Accuracy: 31.1%, Avg loss: 1.991379 \n",
      "\n",
      "batch 30, loss: 2.018399, accuracy: 27.0%\n",
      "Test Error: \n",
      "Accuracy: 31.4%, Avg loss: 1.983954 \n",
      "\n",
      "batch 31, loss: 2.146166, accuracy: 23.4%\n",
      "Test Error: \n",
      "Accuracy: 31.8%, Avg loss: 1.980241 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "batch 0, loss: 1.953764, accuracy: 32.0%\n",
      "Test Error: \n",
      "Accuracy: 32.2%, Avg loss: 1.975744 \n",
      "\n",
      "batch 1, loss: 2.056524, accuracy: 27.7%\n",
      "Test Error: \n",
      "Accuracy: 32.5%, Avg loss: 1.977200 \n",
      "\n",
      "batch 2, loss: 1.979777, accuracy: 31.6%\n",
      "Test Error: \n",
      "Accuracy: 31.9%, Avg loss: 1.975274 \n",
      "\n",
      "batch 3, loss: 1.952803, accuracy: 33.2%\n",
      "Test Error: \n",
      "Accuracy: 32.3%, Avg loss: 1.969976 \n",
      "\n",
      "batch 4, loss: 2.037617, accuracy: 30.1%\n",
      "Test Error: \n",
      "Accuracy: 32.9%, Avg loss: 1.962883 \n",
      "\n",
      "batch 5, loss: 1.973736, accuracy: 30.9%\n",
      "Test Error: \n",
      "Accuracy: 33.1%, Avg loss: 1.952941 \n",
      "\n",
      "batch 6, loss: 1.962065, accuracy: 30.1%\n",
      "Test Error: \n",
      "Accuracy: 33.1%, Avg loss: 1.946387 \n",
      "\n",
      "batch 7, loss: 1.854355, accuracy: 38.3%\n",
      "Test Error: \n",
      "Accuracy: 33.4%, Avg loss: 1.941781 \n",
      "\n",
      "batch 8, loss: 1.972322, accuracy: 30.9%\n",
      "Test Error: \n",
      "Accuracy: 33.0%, Avg loss: 1.933651 \n",
      "\n",
      "batch 9, loss: 1.926691, accuracy: 35.5%\n",
      "Test Error: \n",
      "Accuracy: 33.9%, Avg loss: 1.929120 \n",
      "\n",
      "batch 10, loss: 2.005311, accuracy: 30.9%\n",
      "Test Error: \n",
      "Accuracy: 34.0%, Avg loss: 1.923883 \n",
      "\n",
      "batch 11, loss: 1.861755, accuracy: 37.9%\n",
      "Test Error: \n",
      "Accuracy: 34.2%, Avg loss: 1.919609 \n",
      "\n",
      "batch 12, loss: 1.978507, accuracy: 32.0%\n",
      "Test Error: \n",
      "Accuracy: 35.2%, Avg loss: 1.909526 \n",
      "\n",
      "batch 13, loss: 1.916465, accuracy: 34.8%\n",
      "Test Error: \n",
      "Accuracy: 35.9%, Avg loss: 1.901117 \n",
      "\n",
      "batch 14, loss: 1.966745, accuracy: 30.1%\n",
      "Test Error: \n",
      "Accuracy: 35.8%, Avg loss: 1.897940 \n",
      "\n",
      "batch 15, loss: 1.960483, accuracy: 29.7%\n",
      "Test Error: \n",
      "Accuracy: 36.4%, Avg loss: 1.893484 \n",
      "\n",
      "batch 16, loss: 1.862643, accuracy: 35.5%\n",
      "Test Error: \n",
      "Accuracy: 36.5%, Avg loss: 1.892944 \n",
      "\n",
      "batch 17, loss: 1.936980, accuracy: 34.4%\n",
      "Test Error: \n",
      "Accuracy: 36.6%, Avg loss: 1.891241 \n",
      "\n",
      "batch 18, loss: 1.992775, accuracy: 30.9%\n",
      "Test Error: \n",
      "Accuracy: 36.2%, Avg loss: 1.889814 \n",
      "\n",
      "batch 19, loss: 1.966015, accuracy: 30.5%\n",
      "Test Error: \n",
      "Accuracy: 36.6%, Avg loss: 1.879727 \n",
      "\n",
      "batch 20, loss: 1.897949, accuracy: 33.2%\n",
      "Test Error: \n",
      "Accuracy: 37.0%, Avg loss: 1.872356 \n",
      "\n",
      "batch 21, loss: 1.758561, accuracy: 43.0%\n",
      "Test Error: \n",
      "Accuracy: 37.4%, Avg loss: 1.861437 \n",
      "\n",
      "batch 22, loss: 1.756047, accuracy: 41.4%\n",
      "Test Error: \n",
      "Accuracy: 38.0%, Avg loss: 1.853262 \n",
      "\n",
      "batch 23, loss: 1.864934, accuracy: 36.3%\n",
      "Test Error: \n",
      "Accuracy: 38.1%, Avg loss: 1.845189 \n",
      "\n",
      "batch 24, loss: 1.872189, accuracy: 34.0%\n",
      "Test Error: \n",
      "Accuracy: 38.4%, Avg loss: 1.838564 \n",
      "\n",
      "batch 25, loss: 1.841447, accuracy: 38.7%\n",
      "Test Error: \n",
      "Accuracy: 39.3%, Avg loss: 1.831194 \n",
      "\n",
      "batch 26, loss: 1.858951, accuracy: 37.5%\n",
      "Test Error: \n",
      "Accuracy: 39.7%, Avg loss: 1.821903 \n",
      "\n",
      "batch 27, loss: 1.758042, accuracy: 42.6%\n",
      "Test Error: \n",
      "Accuracy: 39.9%, Avg loss: 1.815539 \n",
      "\n",
      "batch 28, loss: 1.833202, accuracy: 39.8%\n",
      "Test Error: \n",
      "Accuracy: 40.5%, Avg loss: 1.803241 \n",
      "\n",
      "batch 29, loss: 1.952685, accuracy: 33.6%\n",
      "Test Error: \n",
      "Accuracy: 40.6%, Avg loss: 1.798130 \n",
      "\n",
      "batch 30, loss: 1.797987, accuracy: 40.2%\n",
      "Test Error: \n",
      "Accuracy: 41.0%, Avg loss: 1.790892 \n",
      "\n",
      "batch 31, loss: 1.883223, accuracy: 35.9%\n",
      "Test Error: \n",
      "Accuracy: 41.6%, Avg loss: 1.781075 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "batch 0, loss: 1.811568, accuracy: 40.6%\n",
      "Test Error: \n",
      "Accuracy: 42.2%, Avg loss: 1.769546 \n",
      "\n",
      "batch 1, loss: 1.892920, accuracy: 40.2%\n",
      "Test Error: \n",
      "Accuracy: 42.7%, Avg loss: 1.764285 \n",
      "\n",
      "batch 2, loss: 1.689752, accuracy: 46.5%\n",
      "Test Error: \n",
      "Accuracy: 43.4%, Avg loss: 1.752255 \n",
      "\n",
      "batch 3, loss: 1.805072, accuracy: 41.8%\n",
      "Test Error: \n",
      "Accuracy: 43.5%, Avg loss: 1.737559 \n",
      "\n",
      "batch 4, loss: 1.652116, accuracy: 46.5%\n",
      "Test Error: \n",
      "Accuracy: 44.5%, Avg loss: 1.730620 \n",
      "\n",
      "batch 5, loss: 1.785041, accuracy: 40.6%\n",
      "Test Error: \n",
      "Accuracy: 44.8%, Avg loss: 1.724758 \n",
      "\n",
      "batch 6, loss: 1.635443, accuracy: 49.2%\n",
      "Test Error: \n",
      "Accuracy: 44.8%, Avg loss: 1.710988 \n",
      "\n",
      "batch 7, loss: 1.773544, accuracy: 40.2%\n",
      "Test Error: \n",
      "Accuracy: 45.1%, Avg loss: 1.698464 \n",
      "\n",
      "batch 8, loss: 1.682891, accuracy: 47.3%\n",
      "Test Error: \n",
      "Accuracy: 45.8%, Avg loss: 1.688122 \n",
      "\n",
      "batch 9, loss: 1.662909, accuracy: 46.9%\n",
      "Test Error: \n",
      "Accuracy: 46.5%, Avg loss: 1.679992 \n",
      "\n",
      "batch 10, loss: 1.768547, accuracy: 43.0%\n",
      "Test Error: \n",
      "Accuracy: 46.3%, Avg loss: 1.673793 \n",
      "\n",
      "batch 11, loss: 1.708149, accuracy: 43.8%\n",
      "Test Error: \n",
      "Accuracy: 46.2%, Avg loss: 1.673810 \n",
      "\n",
      "batch 12, loss: 1.697982, accuracy: 45.7%\n",
      "Test Error: \n",
      "Accuracy: 46.8%, Avg loss: 1.667690 \n",
      "\n",
      "batch 13, loss: 1.731195, accuracy: 44.9%\n",
      "Test Error: \n",
      "Accuracy: 47.4%, Avg loss: 1.661429 \n",
      "\n",
      "batch 14, loss: 1.750804, accuracy: 43.0%\n",
      "Test Error: \n",
      "Accuracy: 46.9%, Avg loss: 1.656195 \n",
      "\n",
      "batch 15, loss: 1.616616, accuracy: 51.2%\n",
      "Test Error: \n",
      "Accuracy: 46.8%, Avg loss: 1.651586 \n",
      "\n",
      "batch 16, loss: 1.620783, accuracy: 48.0%\n",
      "Test Error: \n",
      "Accuracy: 47.3%, Avg loss: 1.641420 \n",
      "\n",
      "batch 17, loss: 1.675949, accuracy: 44.9%\n",
      "Test Error: \n",
      "Accuracy: 48.2%, Avg loss: 1.630428 \n",
      "\n",
      "batch 18, loss: 1.722505, accuracy: 43.8%\n",
      "Test Error: \n",
      "Accuracy: 48.8%, Avg loss: 1.620656 \n",
      "\n",
      "batch 19, loss: 1.632600, accuracy: 47.3%\n",
      "Test Error: \n",
      "Accuracy: 49.0%, Avg loss: 1.609062 \n",
      "\n",
      "batch 20, loss: 1.605804, accuracy: 50.8%\n",
      "Test Error: \n",
      "Accuracy: 50.0%, Avg loss: 1.591803 \n",
      "\n",
      "batch 21, loss: 1.650983, accuracy: 46.5%\n",
      "Test Error: \n",
      "Accuracy: 50.8%, Avg loss: 1.579206 \n",
      "\n",
      "batch 22, loss: 1.673662, accuracy: 46.9%\n",
      "Test Error: \n",
      "Accuracy: 51.0%, Avg loss: 1.582850 \n",
      "\n",
      "batch 23, loss: 1.637911, accuracy: 50.4%\n",
      "Test Error: \n",
      "Accuracy: 50.8%, Avg loss: 1.589361 \n",
      "\n",
      "batch 24, loss: 1.487524, accuracy: 51.2%\n",
      "Test Error: \n",
      "Accuracy: 50.1%, Avg loss: 1.597965 \n",
      "\n",
      "batch 25, loss: 1.690966, accuracy: 46.5%\n",
      "Test Error: \n",
      "Accuracy: 49.3%, Avg loss: 1.606116 \n",
      "\n",
      "batch 26, loss: 1.548463, accuracy: 47.3%\n",
      "Test Error: \n",
      "Accuracy: 49.2%, Avg loss: 1.606436 \n",
      "\n",
      "batch 27, loss: 1.771928, accuracy: 39.1%\n",
      "Test Error: \n",
      "Accuracy: 49.1%, Avg loss: 1.600919 \n",
      "\n",
      "batch 28, loss: 1.579507, accuracy: 49.6%\n",
      "Test Error: \n",
      "Accuracy: 49.6%, Avg loss: 1.590461 \n",
      "\n",
      "batch 29, loss: 1.681901, accuracy: 46.5%\n",
      "Test Error: \n",
      "Accuracy: 49.8%, Avg loss: 1.582960 \n",
      "\n",
      "batch 30, loss: 1.577918, accuracy: 52.7%\n",
      "Test Error: \n",
      "Accuracy: 50.5%, Avg loss: 1.569322 \n",
      "\n",
      "batch 31, loss: 1.418511, accuracy: 54.7%\n",
      "Test Error: \n",
      "Accuracy: 50.4%, Avg loss: 1.561884 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "batch 0, loss: 1.547573, accuracy: 51.6%\n",
      "Test Error: \n",
      "Accuracy: 50.7%, Avg loss: 1.553680 \n",
      "\n",
      "batch 1, loss: 1.479114, accuracy: 52.3%\n",
      "Test Error: \n",
      "Accuracy: 51.6%, Avg loss: 1.539230 \n",
      "\n",
      "batch 2, loss: 1.563795, accuracy: 46.9%\n",
      "Test Error: \n",
      "Accuracy: 52.4%, Avg loss: 1.524146 \n",
      "\n",
      "batch 3, loss: 1.502407, accuracy: 52.7%\n",
      "Test Error: \n",
      "Accuracy: 53.1%, Avg loss: 1.510781 \n",
      "\n",
      "batch 4, loss: 1.526574, accuracy: 50.8%\n",
      "Test Error: \n",
      "Accuracy: 53.2%, Avg loss: 1.500512 \n",
      "\n",
      "batch 5, loss: 1.492735, accuracy: 55.5%\n",
      "Test Error: \n",
      "Accuracy: 53.1%, Avg loss: 1.491700 \n",
      "\n",
      "batch 6, loss: 1.603708, accuracy: 51.2%\n",
      "Test Error: \n",
      "Accuracy: 53.8%, Avg loss: 1.483263 \n",
      "\n",
      "batch 7, loss: 1.464789, accuracy: 50.8%\n",
      "Test Error: \n",
      "Accuracy: 54.4%, Avg loss: 1.477259 \n",
      "\n",
      "batch 8, loss: 1.495191, accuracy: 52.7%\n",
      "Test Error: \n",
      "Accuracy: 55.3%, Avg loss: 1.471942 \n",
      "\n",
      "batch 9, loss: 1.508682, accuracy: 53.5%\n",
      "Test Error: \n",
      "Accuracy: 55.2%, Avg loss: 1.466120 \n",
      "\n",
      "batch 10, loss: 1.545032, accuracy: 48.8%\n",
      "Test Error: \n",
      "Accuracy: 55.2%, Avg loss: 1.458799 \n",
      "\n",
      "batch 11, loss: 1.524616, accuracy: 52.0%\n",
      "Test Error: \n",
      "Accuracy: 55.2%, Avg loss: 1.454325 \n",
      "\n",
      "batch 12, loss: 1.416379, accuracy: 60.2%\n",
      "Test Error: \n",
      "Accuracy: 55.4%, Avg loss: 1.443967 \n",
      "\n",
      "batch 13, loss: 1.500097, accuracy: 53.1%\n",
      "Test Error: \n",
      "Accuracy: 56.0%, Avg loss: 1.440042 \n",
      "\n",
      "batch 14, loss: 1.381183, accuracy: 60.2%\n",
      "Test Error: \n",
      "Accuracy: 56.9%, Avg loss: 1.434078 \n",
      "\n",
      "batch 15, loss: 1.550359, accuracy: 50.4%\n",
      "Test Error: \n",
      "Accuracy: 56.7%, Avg loss: 1.434153 \n",
      "\n",
      "batch 16, loss: 1.370190, accuracy: 57.8%\n",
      "Test Error: \n",
      "Accuracy: 56.5%, Avg loss: 1.427123 \n",
      "\n",
      "batch 17, loss: 1.480442, accuracy: 55.9%\n",
      "Test Error: \n",
      "Accuracy: 56.5%, Avg loss: 1.424372 \n",
      "\n",
      "batch 18, loss: 1.385138, accuracy: 57.0%\n",
      "Test Error: \n",
      "Accuracy: 56.5%, Avg loss: 1.422817 \n",
      "\n",
      "batch 19, loss: 1.533729, accuracy: 54.3%\n",
      "Test Error: \n",
      "Accuracy: 56.3%, Avg loss: 1.424624 \n",
      "\n",
      "batch 20, loss: 1.509946, accuracy: 53.9%\n",
      "Test Error: \n",
      "Accuracy: 56.2%, Avg loss: 1.422740 \n",
      "\n",
      "batch 21, loss: 1.404073, accuracy: 57.4%\n",
      "Test Error: \n",
      "Accuracy: 56.5%, Avg loss: 1.415025 \n",
      "\n",
      "batch 22, loss: 1.351220, accuracy: 56.6%\n",
      "Test Error: \n",
      "Accuracy: 56.2%, Avg loss: 1.406400 \n",
      "\n",
      "batch 23, loss: 1.418920, accuracy: 60.5%\n",
      "Test Error: \n",
      "Accuracy: 56.5%, Avg loss: 1.397207 \n",
      "\n",
      "batch 24, loss: 1.407286, accuracy: 57.8%\n",
      "Test Error: \n",
      "Accuracy: 56.5%, Avg loss: 1.386854 \n",
      "\n",
      "batch 25, loss: 1.493993, accuracy: 53.9%\n",
      "Test Error: \n",
      "Accuracy: 57.1%, Avg loss: 1.378939 \n",
      "\n",
      "batch 26, loss: 1.371624, accuracy: 59.8%\n",
      "Test Error: \n",
      "Accuracy: 57.4%, Avg loss: 1.372576 \n",
      "\n",
      "batch 27, loss: 1.304062, accuracy: 57.0%\n",
      "Test Error: \n",
      "Accuracy: 57.1%, Avg loss: 1.365597 \n",
      "\n",
      "batch 28, loss: 1.435949, accuracy: 54.3%\n",
      "Test Error: \n",
      "Accuracy: 57.4%, Avg loss: 1.366607 \n",
      "\n",
      "batch 29, loss: 1.390648, accuracy: 57.8%\n",
      "Test Error: \n",
      "Accuracy: 57.8%, Avg loss: 1.360415 \n",
      "\n",
      "batch 30, loss: 1.503636, accuracy: 52.3%\n",
      "Test Error: \n",
      "Accuracy: 58.0%, Avg loss: 1.356868 \n",
      "\n",
      "batch 31, loss: 1.177420, accuracy: 67.2%\n",
      "Test Error: \n",
      "Accuracy: 58.3%, Avg loss: 1.348910 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "batch 0, loss: 1.268320, accuracy: 62.1%\n",
      "Test Error: \n",
      "Accuracy: 58.8%, Avg loss: 1.339301 \n",
      "\n",
      "batch 1, loss: 1.377564, accuracy: 57.8%\n",
      "Test Error: \n",
      "Accuracy: 59.0%, Avg loss: 1.333545 \n",
      "\n",
      "batch 2, loss: 1.398788, accuracy: 56.2%\n",
      "Test Error: \n",
      "Accuracy: 59.2%, Avg loss: 1.329415 \n",
      "\n",
      "batch 3, loss: 1.335989, accuracy: 59.8%\n",
      "Test Error: \n",
      "Accuracy: 59.5%, Avg loss: 1.324215 \n",
      "\n",
      "batch 4, loss: 1.284852, accuracy: 57.8%\n",
      "Test Error: \n",
      "Accuracy: 59.2%, Avg loss: 1.313233 \n",
      "\n",
      "batch 5, loss: 1.277019, accuracy: 59.8%\n",
      "Test Error: \n",
      "Accuracy: 59.9%, Avg loss: 1.306864 \n",
      "\n",
      "batch 6, loss: 1.272792, accuracy: 60.2%\n",
      "Test Error: \n",
      "Accuracy: 59.8%, Avg loss: 1.303358 \n",
      "\n",
      "batch 7, loss: 1.441844, accuracy: 53.9%\n",
      "Test Error: \n",
      "Accuracy: 60.1%, Avg loss: 1.295340 \n",
      "\n",
      "batch 8, loss: 1.296951, accuracy: 62.9%\n",
      "Test Error: \n",
      "Accuracy: 60.2%, Avg loss: 1.294171 \n",
      "\n",
      "batch 9, loss: 1.459328, accuracy: 53.1%\n",
      "Test Error: \n",
      "Accuracy: 60.8%, Avg loss: 1.289370 \n",
      "\n",
      "batch 10, loss: 1.356835, accuracy: 58.6%\n",
      "Test Error: \n",
      "Accuracy: 60.7%, Avg loss: 1.288484 \n",
      "\n",
      "batch 11, loss: 1.330053, accuracy: 60.5%\n",
      "Test Error: \n",
      "Accuracy: 61.1%, Avg loss: 1.285232 \n",
      "\n",
      "batch 12, loss: 1.354208, accuracy: 54.3%\n",
      "Test Error: \n",
      "Accuracy: 61.1%, Avg loss: 1.283948 \n",
      "\n",
      "batch 13, loss: 1.315181, accuracy: 59.4%\n",
      "Test Error: \n",
      "Accuracy: 61.5%, Avg loss: 1.277394 \n",
      "\n",
      "batch 14, loss: 1.373427, accuracy: 55.9%\n",
      "Test Error: \n",
      "Accuracy: 61.5%, Avg loss: 1.272147 \n",
      "\n",
      "batch 15, loss: 1.279145, accuracy: 60.9%\n",
      "Test Error: \n",
      "Accuracy: 61.6%, Avg loss: 1.260910 \n",
      "\n",
      "batch 16, loss: 1.307245, accuracy: 57.0%\n",
      "Test Error: \n",
      "Accuracy: 62.0%, Avg loss: 1.253809 \n",
      "\n",
      "batch 17, loss: 1.209636, accuracy: 63.3%\n",
      "Test Error: \n",
      "Accuracy: 62.4%, Avg loss: 1.246395 \n",
      "\n",
      "batch 18, loss: 1.241981, accuracy: 62.1%\n",
      "Test Error: \n",
      "Accuracy: 62.4%, Avg loss: 1.243567 \n",
      "\n",
      "batch 19, loss: 1.332394, accuracy: 59.0%\n",
      "Test Error: \n",
      "Accuracy: 62.8%, Avg loss: 1.239767 \n",
      "\n",
      "batch 20, loss: 1.315889, accuracy: 60.5%\n",
      "Test Error: \n",
      "Accuracy: 63.1%, Avg loss: 1.238142 \n",
      "\n",
      "batch 21, loss: 1.346723, accuracy: 57.0%\n",
      "Test Error: \n",
      "Accuracy: 63.1%, Avg loss: 1.235200 \n",
      "\n",
      "batch 22, loss: 1.184951, accuracy: 64.1%\n",
      "Test Error: \n",
      "Accuracy: 62.8%, Avg loss: 1.228420 \n",
      "\n",
      "batch 23, loss: 1.250201, accuracy: 67.2%\n",
      "Test Error: \n",
      "Accuracy: 62.5%, Avg loss: 1.225444 \n",
      "\n",
      "batch 24, loss: 1.286334, accuracy: 61.3%\n",
      "Test Error: \n",
      "Accuracy: 62.3%, Avg loss: 1.223632 \n",
      "\n",
      "batch 25, loss: 1.232556, accuracy: 59.0%\n",
      "Test Error: \n",
      "Accuracy: 62.4%, Avg loss: 1.218426 \n",
      "\n",
      "batch 26, loss: 1.359546, accuracy: 60.2%\n",
      "Test Error: \n",
      "Accuracy: 62.7%, Avg loss: 1.217824 \n",
      "\n",
      "batch 27, loss: 1.232598, accuracy: 62.9%\n",
      "Test Error: \n",
      "Accuracy: 62.7%, Avg loss: 1.215362 \n",
      "\n",
      "batch 28, loss: 1.274191, accuracy: 60.9%\n",
      "Test Error: \n",
      "Accuracy: 62.4%, Avg loss: 1.210104 \n",
      "\n",
      "batch 29, loss: 1.150097, accuracy: 66.0%\n",
      "Test Error: \n",
      "Accuracy: 62.8%, Avg loss: 1.204193 \n",
      "\n",
      "batch 30, loss: 1.224242, accuracy: 64.1%\n",
      "Test Error: \n",
      "Accuracy: 62.7%, Avg loss: 1.198959 \n",
      "\n",
      "batch 31, loss: 1.281996, accuracy: 59.4%\n",
      "Test Error: \n",
      "Accuracy: 62.7%, Avg loss: 1.201598 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "batch 0, loss: 1.230364, accuracy: 61.3%\n",
      "Test Error: \n",
      "Accuracy: 63.0%, Avg loss: 1.194095 \n",
      "\n",
      "batch 1, loss: 1.123034, accuracy: 61.7%\n",
      "Test Error: \n",
      "Accuracy: 62.8%, Avg loss: 1.188907 \n",
      "\n",
      "batch 2, loss: 1.312218, accuracy: 60.2%\n",
      "Test Error: \n",
      "Accuracy: 62.4%, Avg loss: 1.185673 \n",
      "\n",
      "batch 3, loss: 1.252213, accuracy: 64.5%\n",
      "Test Error: \n",
      "Accuracy: 62.5%, Avg loss: 1.181881 \n",
      "\n",
      "batch 4, loss: 1.264683, accuracy: 60.9%\n",
      "Test Error: \n",
      "Accuracy: 63.3%, Avg loss: 1.172853 \n",
      "\n",
      "batch 5, loss: 1.080728, accuracy: 64.5%\n",
      "Test Error: \n",
      "Accuracy: 63.7%, Avg loss: 1.165099 \n",
      "\n",
      "batch 6, loss: 1.220426, accuracy: 60.5%\n",
      "Test Error: \n",
      "Accuracy: 64.6%, Avg loss: 1.164296 \n",
      "\n",
      "batch 7, loss: 1.206766, accuracy: 64.5%\n",
      "Test Error: \n",
      "Accuracy: 63.8%, Avg loss: 1.159142 \n",
      "\n",
      "batch 8, loss: 1.218859, accuracy: 63.3%\n",
      "Test Error: \n",
      "Accuracy: 63.7%, Avg loss: 1.156038 \n",
      "\n",
      "batch 9, loss: 1.209912, accuracy: 61.7%\n",
      "Test Error: \n",
      "Accuracy: 64.2%, Avg loss: 1.150703 \n",
      "\n",
      "batch 10, loss: 1.269184, accuracy: 62.5%\n",
      "Test Error: \n",
      "Accuracy: 64.3%, Avg loss: 1.146639 \n",
      "\n",
      "batch 11, loss: 1.240353, accuracy: 63.3%\n",
      "Test Error: \n",
      "Accuracy: 64.6%, Avg loss: 1.141570 \n",
      "\n",
      "batch 12, loss: 1.082391, accuracy: 64.1%\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 1.136082 \n",
      "\n",
      "batch 13, loss: 1.190720, accuracy: 61.7%\n",
      "Test Error: \n",
      "Accuracy: 65.2%, Avg loss: 1.132767 \n",
      "\n",
      "batch 14, loss: 1.177144, accuracy: 64.8%\n",
      "Test Error: \n",
      "Accuracy: 65.4%, Avg loss: 1.127928 \n",
      "\n",
      "batch 15, loss: 1.141180, accuracy: 62.9%\n",
      "Test Error: \n",
      "Accuracy: 65.5%, Avg loss: 1.122096 \n",
      "\n",
      "batch 16, loss: 1.126422, accuracy: 66.4%\n",
      "Test Error: \n",
      "Accuracy: 65.3%, Avg loss: 1.119187 \n",
      "\n",
      "batch 17, loss: 1.351630, accuracy: 55.1%\n",
      "Test Error: \n",
      "Accuracy: 65.5%, Avg loss: 1.116755 \n",
      "\n",
      "batch 18, loss: 0.995828, accuracy: 70.7%\n",
      "Test Error: \n",
      "Accuracy: 66.1%, Avg loss: 1.108726 \n",
      "\n",
      "batch 19, loss: 1.012746, accuracy: 70.3%\n",
      "Test Error: \n",
      "Accuracy: 66.1%, Avg loss: 1.102433 \n",
      "\n",
      "batch 20, loss: 1.044391, accuracy: 70.3%\n",
      "Test Error: \n",
      "Accuracy: 66.8%, Avg loss: 1.095396 \n",
      "\n",
      "batch 21, loss: 1.174363, accuracy: 62.9%\n",
      "Test Error: \n",
      "Accuracy: 66.8%, Avg loss: 1.087772 \n",
      "\n",
      "batch 22, loss: 1.134926, accuracy: 64.1%\n",
      "Test Error: \n",
      "Accuracy: 67.0%, Avg loss: 1.077406 \n",
      "\n",
      "batch 23, loss: 1.099215, accuracy: 68.8%\n",
      "Test Error: \n",
      "Accuracy: 66.8%, Avg loss: 1.067485 \n",
      "\n",
      "batch 24, loss: 1.210113, accuracy: 60.9%\n",
      "Test Error: \n",
      "Accuracy: 67.3%, Avg loss: 1.060865 \n",
      "\n",
      "batch 25, loss: 1.074091, accuracy: 67.2%\n",
      "Test Error: \n",
      "Accuracy: 67.3%, Avg loss: 1.055487 \n",
      "\n",
      "batch 26, loss: 0.957709, accuracy: 70.3%\n",
      "Test Error: \n",
      "Accuracy: 67.5%, Avg loss: 1.052446 \n",
      "\n",
      "batch 27, loss: 1.087777, accuracy: 61.7%\n",
      "Test Error: \n",
      "Accuracy: 67.5%, Avg loss: 1.045216 \n",
      "\n",
      "batch 28, loss: 1.083518, accuracy: 67.6%\n",
      "Test Error: \n",
      "Accuracy: 67.5%, Avg loss: 1.038950 \n",
      "\n",
      "batch 29, loss: 1.074768, accuracy: 66.8%\n",
      "Test Error: \n",
      "Accuracy: 68.0%, Avg loss: 1.034865 \n",
      "\n",
      "batch 30, loss: 1.115686, accuracy: 64.8%\n",
      "Test Error: \n",
      "Accuracy: 68.5%, Avg loss: 1.026451 \n",
      "\n",
      "batch 31, loss: 1.144139, accuracy: 64.1%\n",
      "Test Error: \n",
      "Accuracy: 68.7%, Avg loss: 1.019382 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "batch 0, loss: 1.031536, accuracy: 68.4%\n",
      "Test Error: \n",
      "Accuracy: 68.4%, Avg loss: 1.016323 \n",
      "\n",
      "batch 1, loss: 0.996881, accuracy: 69.1%\n",
      "Test Error: \n",
      "Accuracy: 68.5%, Avg loss: 1.010486 \n",
      "\n",
      "batch 2, loss: 1.133083, accuracy: 63.3%\n",
      "Test Error: \n",
      "Accuracy: 68.3%, Avg loss: 1.006170 \n",
      "\n",
      "batch 3, loss: 1.063555, accuracy: 68.8%\n",
      "Test Error: \n",
      "Accuracy: 68.7%, Avg loss: 1.005217 \n",
      "\n",
      "batch 4, loss: 0.967803, accuracy: 66.8%\n",
      "Test Error: \n",
      "Accuracy: 68.5%, Avg loss: 1.003637 \n",
      "\n",
      "batch 5, loss: 0.872159, accuracy: 77.7%\n",
      "Test Error: \n",
      "Accuracy: 68.3%, Avg loss: 1.003126 \n",
      "\n",
      "batch 6, loss: 1.062097, accuracy: 66.8%\n",
      "Test Error: \n",
      "Accuracy: 68.8%, Avg loss: 0.997894 \n",
      "\n",
      "batch 7, loss: 1.011328, accuracy: 70.3%\n",
      "Test Error: \n",
      "Accuracy: 68.7%, Avg loss: 0.989231 \n",
      "\n",
      "batch 8, loss: 1.148831, accuracy: 63.3%\n",
      "Test Error: \n",
      "Accuracy: 69.0%, Avg loss: 0.983260 \n",
      "\n",
      "batch 9, loss: 0.985420, accuracy: 67.2%\n",
      "Test Error: \n",
      "Accuracy: 69.8%, Avg loss: 0.970550 \n",
      "\n",
      "batch 10, loss: 0.916379, accuracy: 71.1%\n",
      "Test Error: \n",
      "Accuracy: 70.3%, Avg loss: 0.960253 \n",
      "\n",
      "batch 11, loss: 1.021530, accuracy: 70.3%\n",
      "Test Error: \n",
      "Accuracy: 70.2%, Avg loss: 0.952018 \n",
      "\n",
      "batch 12, loss: 1.044559, accuracy: 62.5%\n",
      "Test Error: \n",
      "Accuracy: 70.9%, Avg loss: 0.944053 \n",
      "\n",
      "batch 13, loss: 0.872763, accuracy: 72.7%\n",
      "Test Error: \n",
      "Accuracy: 71.0%, Avg loss: 0.941011 \n",
      "\n",
      "batch 14, loss: 1.000343, accuracy: 67.6%\n",
      "Test Error: \n",
      "Accuracy: 71.2%, Avg loss: 0.934247 \n",
      "\n",
      "batch 15, loss: 0.943121, accuracy: 72.3%\n",
      "Test Error: \n",
      "Accuracy: 71.6%, Avg loss: 0.928268 \n",
      "\n",
      "batch 16, loss: 0.897266, accuracy: 71.9%\n",
      "Test Error: \n",
      "Accuracy: 71.7%, Avg loss: 0.924327 \n",
      "\n",
      "batch 17, loss: 0.911388, accuracy: 70.7%\n",
      "Test Error: \n",
      "Accuracy: 71.5%, Avg loss: 0.920373 \n",
      "\n",
      "batch 18, loss: 0.930413, accuracy: 70.3%\n",
      "Test Error: \n",
      "Accuracy: 71.0%, Avg loss: 0.912028 \n",
      "\n",
      "batch 19, loss: 0.886091, accuracy: 72.3%\n",
      "Test Error: \n",
      "Accuracy: 71.6%, Avg loss: 0.902564 \n",
      "\n",
      "batch 20, loss: 0.837190, accuracy: 74.2%\n",
      "Test Error: \n",
      "Accuracy: 72.0%, Avg loss: 0.898698 \n",
      "\n",
      "batch 21, loss: 0.965444, accuracy: 68.0%\n",
      "Test Error: \n",
      "Accuracy: 72.0%, Avg loss: 0.892267 \n",
      "\n",
      "batch 22, loss: 0.878172, accuracy: 72.3%\n",
      "Test Error: \n",
      "Accuracy: 71.9%, Avg loss: 0.885825 \n",
      "\n",
      "batch 23, loss: 0.828041, accuracy: 76.2%\n",
      "Test Error: \n",
      "Accuracy: 72.0%, Avg loss: 0.882538 \n",
      "\n",
      "batch 24, loss: 0.917972, accuracy: 70.7%\n",
      "Test Error: \n",
      "Accuracy: 72.4%, Avg loss: 0.872419 \n",
      "\n",
      "batch 25, loss: 1.034846, accuracy: 63.3%\n",
      "Test Error: \n",
      "Accuracy: 72.9%, Avg loss: 0.870663 \n",
      "\n",
      "batch 26, loss: 0.985403, accuracy: 68.0%\n",
      "Test Error: \n",
      "Accuracy: 72.5%, Avg loss: 0.866041 \n",
      "\n",
      "batch 27, loss: 0.848803, accuracy: 75.4%\n",
      "Test Error: \n",
      "Accuracy: 72.5%, Avg loss: 0.863633 \n",
      "\n",
      "batch 28, loss: 0.928094, accuracy: 67.6%\n",
      "Test Error: \n",
      "Accuracy: 72.9%, Avg loss: 0.857683 \n",
      "\n",
      "batch 29, loss: 0.866171, accuracy: 75.4%\n",
      "Test Error: \n",
      "Accuracy: 72.8%, Avg loss: 0.854007 \n",
      "\n",
      "batch 30, loss: 0.870495, accuracy: 74.2%\n",
      "Test Error: \n",
      "Accuracy: 72.9%, Avg loss: 0.845979 \n",
      "\n",
      "batch 31, loss: 0.713329, accuracy: 76.6%\n",
      "Test Error: \n",
      "Accuracy: 73.0%, Avg loss: 0.845010 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "batch 0, loss: 0.800382, accuracy: 72.7%\n",
      "Test Error: \n",
      "Accuracy: 73.7%, Avg loss: 0.835931 \n",
      "\n",
      "batch 1, loss: 0.861934, accuracy: 73.8%\n",
      "Test Error: \n",
      "Accuracy: 74.2%, Avg loss: 0.827910 \n",
      "\n",
      "batch 2, loss: 0.792434, accuracy: 73.8%\n",
      "Test Error: \n",
      "Accuracy: 74.4%, Avg loss: 0.820870 \n",
      "\n",
      "batch 3, loss: 0.775342, accuracy: 77.7%\n",
      "Test Error: \n",
      "Accuracy: 74.2%, Avg loss: 0.817860 \n",
      "\n",
      "batch 4, loss: 0.836217, accuracy: 71.5%\n",
      "Test Error: \n",
      "Accuracy: 74.5%, Avg loss: 0.811601 \n",
      "\n",
      "batch 5, loss: 0.927321, accuracy: 68.4%\n",
      "Test Error: \n",
      "Accuracy: 74.8%, Avg loss: 0.807450 \n",
      "\n",
      "batch 6, loss: 0.775936, accuracy: 77.7%\n",
      "Test Error: \n",
      "Accuracy: 75.0%, Avg loss: 0.804711 \n",
      "\n",
      "batch 7, loss: 0.819123, accuracy: 73.0%\n",
      "Test Error: \n",
      "Accuracy: 75.1%, Avg loss: 0.801927 \n",
      "\n",
      "batch 8, loss: 0.864245, accuracy: 74.2%\n",
      "Test Error: \n",
      "Accuracy: 75.0%, Avg loss: 0.798494 \n",
      "\n",
      "batch 9, loss: 0.847512, accuracy: 74.6%\n",
      "Test Error: \n",
      "Accuracy: 75.3%, Avg loss: 0.794138 \n",
      "\n",
      "batch 10, loss: 0.740183, accuracy: 77.7%\n",
      "Test Error: \n",
      "Accuracy: 75.7%, Avg loss: 0.786215 \n",
      "\n",
      "batch 11, loss: 0.748588, accuracy: 78.5%\n",
      "Test Error: \n",
      "Accuracy: 75.6%, Avg loss: 0.780016 \n",
      "\n",
      "batch 12, loss: 0.784772, accuracy: 74.6%\n",
      "Test Error: \n",
      "Accuracy: 75.9%, Avg loss: 0.772416 \n",
      "\n",
      "batch 13, loss: 0.807752, accuracy: 75.0%\n",
      "Test Error: \n",
      "Accuracy: 76.3%, Avg loss: 0.765977 \n",
      "\n",
      "batch 14, loss: 0.767840, accuracy: 77.7%\n",
      "Test Error: \n",
      "Accuracy: 76.1%, Avg loss: 0.759628 \n",
      "\n",
      "batch 15, loss: 0.694912, accuracy: 80.5%\n",
      "Test Error: \n",
      "Accuracy: 76.8%, Avg loss: 0.756607 \n",
      "\n",
      "batch 16, loss: 0.721078, accuracy: 79.3%\n",
      "Test Error: \n",
      "Accuracy: 77.0%, Avg loss: 0.751793 \n",
      "\n",
      "batch 17, loss: 0.839599, accuracy: 73.0%\n",
      "Test Error: \n",
      "Accuracy: 77.4%, Avg loss: 0.744653 \n",
      "\n",
      "batch 18, loss: 0.752210, accuracy: 77.3%\n",
      "Test Error: \n",
      "Accuracy: 77.6%, Avg loss: 0.736482 \n",
      "\n",
      "batch 19, loss: 0.747781, accuracy: 77.3%\n",
      "Test Error: \n",
      "Accuracy: 77.5%, Avg loss: 0.734107 \n",
      "\n",
      "batch 20, loss: 0.756049, accuracy: 75.4%\n",
      "Test Error: \n",
      "Accuracy: 78.1%, Avg loss: 0.727090 \n",
      "\n",
      "batch 21, loss: 0.832987, accuracy: 72.7%\n",
      "Test Error: \n",
      "Accuracy: 78.7%, Avg loss: 0.722812 \n",
      "\n",
      "batch 22, loss: 0.753587, accuracy: 75.8%\n",
      "Test Error: \n",
      "Accuracy: 78.9%, Avg loss: 0.711102 \n",
      "\n",
      "batch 23, loss: 0.703267, accuracy: 77.3%\n",
      "Test Error: \n",
      "Accuracy: 79.1%, Avg loss: 0.706033 \n",
      "\n",
      "batch 24, loss: 0.712079, accuracy: 78.9%\n",
      "Test Error: \n",
      "Accuracy: 78.7%, Avg loss: 0.703230 \n",
      "\n",
      "batch 25, loss: 0.714389, accuracy: 78.5%\n",
      "Test Error: \n",
      "Accuracy: 79.2%, Avg loss: 0.695619 \n",
      "\n",
      "batch 26, loss: 0.703399, accuracy: 77.0%\n",
      "Test Error: \n",
      "Accuracy: 79.3%, Avg loss: 0.691205 \n",
      "\n",
      "batch 27, loss: 0.767647, accuracy: 75.0%\n",
      "Test Error: \n",
      "Accuracy: 79.7%, Avg loss: 0.687841 \n",
      "\n",
      "batch 28, loss: 0.730380, accuracy: 77.7%\n",
      "Test Error: \n",
      "Accuracy: 79.0%, Avg loss: 0.688344 \n",
      "\n",
      "batch 29, loss: 0.677219, accuracy: 78.9%\n",
      "Test Error: \n",
      "Accuracy: 79.0%, Avg loss: 0.686699 \n",
      "\n",
      "batch 30, loss: 0.692617, accuracy: 79.7%\n",
      "Test Error: \n",
      "Accuracy: 79.1%, Avg loss: 0.685964 \n",
      "\n",
      "batch 31, loss: 0.679231, accuracy: 79.7%\n",
      "Test Error: \n",
      "Accuracy: 79.1%, Avg loss: 0.683259 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "batch 0, loss: 0.711128, accuracy: 78.5%\n",
      "Test Error: \n",
      "Accuracy: 79.7%, Avg loss: 0.681029 \n",
      "\n",
      "batch 1, loss: 0.646692, accuracy: 77.3%\n",
      "Test Error: \n",
      "Accuracy: 79.9%, Avg loss: 0.679591 \n",
      "\n",
      "batch 2, loss: 0.733842, accuracy: 76.6%\n",
      "Test Error: \n",
      "Accuracy: 79.3%, Avg loss: 0.679278 \n",
      "\n",
      "batch 3, loss: 0.730434, accuracy: 77.3%\n",
      "Test Error: \n",
      "Accuracy: 80.0%, Avg loss: 0.675452 \n",
      "\n",
      "batch 4, loss: 0.691830, accuracy: 80.1%\n",
      "Test Error: \n",
      "Accuracy: 79.8%, Avg loss: 0.670345 \n",
      "\n",
      "batch 5, loss: 0.738299, accuracy: 79.7%\n",
      "Test Error: \n",
      "Accuracy: 80.0%, Avg loss: 0.664180 \n",
      "\n",
      "batch 6, loss: 0.629449, accuracy: 81.2%\n",
      "Test Error: \n",
      "Accuracy: 80.0%, Avg loss: 0.662129 \n",
      "\n",
      "batch 7, loss: 0.714479, accuracy: 77.7%\n",
      "Test Error: \n",
      "Accuracy: 80.5%, Avg loss: 0.658773 \n",
      "\n",
      "batch 8, loss: 0.683189, accuracy: 78.5%\n",
      "Test Error: \n",
      "Accuracy: 80.5%, Avg loss: 0.654841 \n",
      "\n",
      "batch 9, loss: 0.589638, accuracy: 82.4%\n",
      "Test Error: \n",
      "Accuracy: 80.7%, Avg loss: 0.653845 \n",
      "\n",
      "batch 10, loss: 0.720340, accuracy: 78.9%\n",
      "Test Error: \n",
      "Accuracy: 80.5%, Avg loss: 0.651138 \n",
      "\n",
      "batch 11, loss: 0.587292, accuracy: 82.0%\n",
      "Test Error: \n",
      "Accuracy: 80.2%, Avg loss: 0.646578 \n",
      "\n",
      "batch 12, loss: 0.633423, accuracy: 79.3%\n",
      "Test Error: \n",
      "Accuracy: 80.2%, Avg loss: 0.647100 \n",
      "\n",
      "batch 13, loss: 0.641328, accuracy: 80.1%\n",
      "Test Error: \n",
      "Accuracy: 79.8%, Avg loss: 0.645675 \n",
      "\n",
      "batch 14, loss: 0.709318, accuracy: 78.9%\n",
      "Test Error: \n",
      "Accuracy: 79.8%, Avg loss: 0.641834 \n",
      "\n",
      "batch 15, loss: 0.632426, accuracy: 78.9%\n",
      "Test Error: \n",
      "Accuracy: 79.7%, Avg loss: 0.639205 \n",
      "\n",
      "batch 16, loss: 0.719826, accuracy: 76.2%\n",
      "Test Error: \n",
      "Accuracy: 79.8%, Avg loss: 0.635494 \n",
      "\n",
      "batch 17, loss: 0.651509, accuracy: 78.1%\n",
      "Test Error: \n",
      "Accuracy: 80.3%, Avg loss: 0.627619 \n",
      "\n",
      "batch 18, loss: 0.659127, accuracy: 77.7%\n",
      "Test Error: \n",
      "Accuracy: 80.5%, Avg loss: 0.625295 \n",
      "\n",
      "batch 19, loss: 0.655842, accuracy: 81.2%\n",
      "Test Error: \n",
      "Accuracy: 81.0%, Avg loss: 0.619523 \n",
      "\n",
      "batch 20, loss: 0.604300, accuracy: 82.4%\n",
      "Test Error: \n",
      "Accuracy: 81.2%, Avg loss: 0.612194 \n",
      "\n",
      "batch 21, loss: 0.630798, accuracy: 83.2%\n",
      "Test Error: \n",
      "Accuracy: 81.3%, Avg loss: 0.606006 \n",
      "\n",
      "batch 22, loss: 0.616001, accuracy: 80.9%\n",
      "Test Error: \n",
      "Accuracy: 81.6%, Avg loss: 0.609400 \n",
      "\n",
      "batch 23, loss: 0.556214, accuracy: 84.8%\n",
      "Test Error: \n",
      "Accuracy: 81.8%, Avg loss: 0.608082 \n",
      "\n",
      "batch 24, loss: 0.564516, accuracy: 82.0%\n",
      "Test Error: \n",
      "Accuracy: 81.7%, Avg loss: 0.608682 \n",
      "\n",
      "batch 25, loss: 0.543095, accuracy: 83.6%\n",
      "Test Error: \n",
      "Accuracy: 81.8%, Avg loss: 0.607054 \n",
      "\n",
      "batch 26, loss: 0.725891, accuracy: 77.0%\n",
      "Test Error: \n",
      "Accuracy: 82.2%, Avg loss: 0.598650 \n",
      "\n",
      "batch 27, loss: 0.565839, accuracy: 82.8%\n",
      "Test Error: \n",
      "Accuracy: 81.8%, Avg loss: 0.598236 \n",
      "\n",
      "batch 28, loss: 0.598077, accuracy: 82.4%\n",
      "Test Error: \n",
      "Accuracy: 82.0%, Avg loss: 0.597429 \n",
      "\n",
      "batch 29, loss: 0.519827, accuracy: 85.9%\n",
      "Test Error: \n",
      "Accuracy: 82.2%, Avg loss: 0.594219 \n",
      "\n",
      "batch 30, loss: 0.616135, accuracy: 81.2%\n",
      "Test Error: \n",
      "Accuracy: 82.7%, Avg loss: 0.594077 \n",
      "\n",
      "batch 31, loss: 0.662971, accuracy: 75.0%\n",
      "Test Error: \n",
      "Accuracy: 82.9%, Avg loss: 0.591262 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "batch 0, loss: 0.570384, accuracy: 82.0%\n",
      "Test Error: \n",
      "Accuracy: 83.0%, Avg loss: 0.585576 \n",
      "\n",
      "batch 1, loss: 0.581017, accuracy: 83.2%\n",
      "Test Error: \n",
      "Accuracy: 83.1%, Avg loss: 0.582407 \n",
      "\n",
      "batch 2, loss: 0.616631, accuracy: 82.0%\n",
      "Test Error: \n",
      "Accuracy: 83.4%, Avg loss: 0.579747 \n",
      "\n",
      "batch 3, loss: 0.594823, accuracy: 84.4%\n",
      "Test Error: \n",
      "Accuracy: 83.7%, Avg loss: 0.582487 \n",
      "\n",
      "batch 4, loss: 0.604116, accuracy: 83.2%\n",
      "Test Error: \n",
      "Accuracy: 83.4%, Avg loss: 0.581501 \n",
      "\n",
      "batch 5, loss: 0.643997, accuracy: 80.9%\n",
      "Test Error: \n",
      "Accuracy: 83.2%, Avg loss: 0.579153 \n",
      "\n",
      "batch 6, loss: 0.657185, accuracy: 80.5%\n",
      "Test Error: \n",
      "Accuracy: 83.2%, Avg loss: 0.575436 \n",
      "\n",
      "batch 7, loss: 0.580855, accuracy: 80.9%\n",
      "Test Error: \n",
      "Accuracy: 83.2%, Avg loss: 0.572686 \n",
      "\n",
      "batch 8, loss: 0.534368, accuracy: 82.4%\n",
      "Test Error: \n",
      "Accuracy: 83.1%, Avg loss: 0.571625 \n",
      "\n",
      "batch 9, loss: 0.618710, accuracy: 82.0%\n",
      "Test Error: \n",
      "Accuracy: 83.3%, Avg loss: 0.569703 \n",
      "\n",
      "batch 10, loss: 0.610993, accuracy: 79.7%\n",
      "Test Error: \n",
      "Accuracy: 83.8%, Avg loss: 0.563076 \n",
      "\n",
      "batch 11, loss: 0.609762, accuracy: 81.6%\n",
      "Test Error: \n",
      "Accuracy: 83.9%, Avg loss: 0.560723 \n",
      "\n",
      "batch 12, loss: 0.568448, accuracy: 82.0%\n",
      "Test Error: \n",
      "Accuracy: 84.0%, Avg loss: 0.552324 \n",
      "\n",
      "batch 13, loss: 0.518999, accuracy: 85.5%\n",
      "Test Error: \n",
      "Accuracy: 84.0%, Avg loss: 0.549652 \n",
      "\n",
      "batch 14, loss: 0.593599, accuracy: 83.2%\n",
      "Test Error: \n",
      "Accuracy: 84.6%, Avg loss: 0.545206 \n",
      "\n",
      "batch 15, loss: 0.483764, accuracy: 86.7%\n",
      "Test Error: \n",
      "Accuracy: 84.4%, Avg loss: 0.542932 \n",
      "\n",
      "batch 16, loss: 0.551480, accuracy: 83.6%\n",
      "Test Error: \n",
      "Accuracy: 84.4%, Avg loss: 0.540985 \n",
      "\n",
      "batch 17, loss: 0.535913, accuracy: 84.4%\n",
      "Test Error: \n",
      "Accuracy: 84.8%, Avg loss: 0.537556 \n",
      "\n",
      "batch 18, loss: 0.556413, accuracy: 82.0%\n",
      "Test Error: \n",
      "Accuracy: 85.4%, Avg loss: 0.537998 \n",
      "\n",
      "batch 19, loss: 0.543425, accuracy: 82.8%\n",
      "Test Error: \n",
      "Accuracy: 85.5%, Avg loss: 0.536981 \n",
      "\n",
      "batch 20, loss: 0.627932, accuracy: 79.3%\n",
      "Test Error: \n",
      "Accuracy: 85.4%, Avg loss: 0.535366 \n",
      "\n",
      "batch 21, loss: 0.570828, accuracy: 84.8%\n",
      "Test Error: \n",
      "Accuracy: 85.2%, Avg loss: 0.532548 \n",
      "\n",
      "batch 22, loss: 0.506616, accuracy: 85.2%\n",
      "Test Error: \n",
      "Accuracy: 85.4%, Avg loss: 0.524848 \n",
      "\n",
      "batch 23, loss: 0.527146, accuracy: 84.0%\n",
      "Test Error: \n",
      "Accuracy: 85.2%, Avg loss: 0.521188 \n",
      "\n",
      "batch 24, loss: 0.595560, accuracy: 81.2%\n",
      "Test Error: \n",
      "Accuracy: 85.4%, Avg loss: 0.518561 \n",
      "\n",
      "batch 25, loss: 0.509517, accuracy: 84.0%\n",
      "Test Error: \n",
      "Accuracy: 85.2%, Avg loss: 0.517563 \n",
      "\n",
      "batch 26, loss: 0.549609, accuracy: 86.3%\n",
      "Test Error: \n",
      "Accuracy: 85.7%, Avg loss: 0.515649 \n",
      "\n",
      "batch 27, loss: 0.441475, accuracy: 88.3%\n",
      "Test Error: \n",
      "Accuracy: 85.4%, Avg loss: 0.516306 \n",
      "\n",
      "batch 28, loss: 0.479790, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 85.3%, Avg loss: 0.513602 \n",
      "\n",
      "batch 29, loss: 0.575385, accuracy: 81.2%\n",
      "Test Error: \n",
      "Accuracy: 85.0%, Avg loss: 0.512736 \n",
      "\n",
      "batch 30, loss: 0.495138, accuracy: 84.8%\n",
      "Test Error: \n",
      "Accuracy: 84.9%, Avg loss: 0.513034 \n",
      "\n",
      "batch 31, loss: 0.532441, accuracy: 84.4%\n",
      "Test Error: \n",
      "Accuracy: 85.0%, Avg loss: 0.511540 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "batch 0, loss: 0.510232, accuracy: 84.0%\n",
      "Test Error: \n",
      "Accuracy: 85.4%, Avg loss: 0.508314 \n",
      "\n",
      "batch 1, loss: 0.532181, accuracy: 85.2%\n",
      "Test Error: \n",
      "Accuracy: 85.5%, Avg loss: 0.508087 \n",
      "\n",
      "batch 2, loss: 0.524008, accuracy: 84.0%\n",
      "Test Error: \n",
      "Accuracy: 85.2%, Avg loss: 0.505377 \n",
      "\n",
      "batch 3, loss: 0.553624, accuracy: 85.2%\n",
      "Test Error: \n",
      "Accuracy: 85.2%, Avg loss: 0.504860 \n",
      "\n",
      "batch 4, loss: 0.523922, accuracy: 84.4%\n",
      "Test Error: \n",
      "Accuracy: 85.3%, Avg loss: 0.503826 \n",
      "\n",
      "batch 5, loss: 0.503657, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 85.4%, Avg loss: 0.502781 \n",
      "\n",
      "batch 6, loss: 0.522377, accuracy: 84.4%\n",
      "Test Error: \n",
      "Accuracy: 85.3%, Avg loss: 0.499200 \n",
      "\n",
      "batch 7, loss: 0.509016, accuracy: 82.4%\n",
      "Test Error: \n",
      "Accuracy: 85.5%, Avg loss: 0.493257 \n",
      "\n",
      "batch 8, loss: 0.530756, accuracy: 83.2%\n",
      "Test Error: \n",
      "Accuracy: 85.5%, Avg loss: 0.487577 \n",
      "\n",
      "batch 9, loss: 0.469215, accuracy: 86.3%\n",
      "Test Error: \n",
      "Accuracy: 86.0%, Avg loss: 0.482071 \n",
      "\n",
      "batch 10, loss: 0.535606, accuracy: 83.6%\n",
      "Test Error: \n",
      "Accuracy: 85.8%, Avg loss: 0.481521 \n",
      "\n",
      "batch 11, loss: 0.474223, accuracy: 83.2%\n",
      "Test Error: \n",
      "Accuracy: 86.2%, Avg loss: 0.480208 \n",
      "\n",
      "batch 12, loss: 0.503493, accuracy: 82.4%\n",
      "Test Error: \n",
      "Accuracy: 86.2%, Avg loss: 0.476796 \n",
      "\n",
      "batch 13, loss: 0.503417, accuracy: 86.7%\n",
      "Test Error: \n",
      "Accuracy: 86.5%, Avg loss: 0.476170 \n",
      "\n",
      "batch 14, loss: 0.416365, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 86.1%, Avg loss: 0.479571 \n",
      "\n",
      "batch 15, loss: 0.448163, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 86.0%, Avg loss: 0.478028 \n",
      "\n",
      "batch 16, loss: 0.450533, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 86.2%, Avg loss: 0.472447 \n",
      "\n",
      "batch 17, loss: 0.487864, accuracy: 85.9%\n",
      "Test Error: \n",
      "Accuracy: 86.2%, Avg loss: 0.468515 \n",
      "\n",
      "batch 18, loss: 0.497146, accuracy: 87.1%\n",
      "Test Error: \n",
      "Accuracy: 86.1%, Avg loss: 0.466485 \n",
      "\n",
      "batch 19, loss: 0.469607, accuracy: 85.2%\n",
      "Test Error: \n",
      "Accuracy: 86.3%, Avg loss: 0.462956 \n",
      "\n",
      "batch 20, loss: 0.479403, accuracy: 85.5%\n",
      "Test Error: \n",
      "Accuracy: 86.2%, Avg loss: 0.461970 \n",
      "\n",
      "batch 21, loss: 0.498129, accuracy: 83.6%\n",
      "Test Error: \n",
      "Accuracy: 86.6%, Avg loss: 0.455731 \n",
      "\n",
      "batch 22, loss: 0.533608, accuracy: 82.8%\n",
      "Test Error: \n",
      "Accuracy: 86.6%, Avg loss: 0.450400 \n",
      "\n",
      "batch 23, loss: 0.438999, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 86.9%, Avg loss: 0.448751 \n",
      "\n",
      "batch 24, loss: 0.445524, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 87.0%, Avg loss: 0.446288 \n",
      "\n",
      "batch 25, loss: 0.515049, accuracy: 85.2%\n",
      "Test Error: \n",
      "Accuracy: 87.0%, Avg loss: 0.446983 \n",
      "\n",
      "batch 26, loss: 0.406354, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 87.0%, Avg loss: 0.448211 \n",
      "\n",
      "batch 27, loss: 0.416834, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 86.5%, Avg loss: 0.449370 \n",
      "\n",
      "batch 28, loss: 0.413243, accuracy: 88.3%\n",
      "Test Error: \n",
      "Accuracy: 87.0%, Avg loss: 0.445442 \n",
      "\n",
      "batch 29, loss: 0.443088, accuracy: 84.8%\n",
      "Test Error: \n",
      "Accuracy: 86.8%, Avg loss: 0.445982 \n",
      "\n",
      "batch 30, loss: 0.463907, accuracy: 85.5%\n",
      "Test Error: \n",
      "Accuracy: 87.1%, Avg loss: 0.447228 \n",
      "\n",
      "batch 31, loss: 0.524723, accuracy: 84.4%\n",
      "Test Error: \n",
      "Accuracy: 87.5%, Avg loss: 0.445590 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "batch 0, loss: 0.444629, accuracy: 87.1%\n",
      "Test Error: \n",
      "Accuracy: 87.8%, Avg loss: 0.441336 \n",
      "\n",
      "batch 1, loss: 0.474893, accuracy: 86.7%\n",
      "Test Error: \n",
      "Accuracy: 87.8%, Avg loss: 0.436259 \n",
      "\n",
      "batch 2, loss: 0.420110, accuracy: 86.3%\n",
      "Test Error: \n",
      "Accuracy: 88.0%, Avg loss: 0.433177 \n",
      "\n",
      "batch 3, loss: 0.445972, accuracy: 85.2%\n",
      "Test Error: \n",
      "Accuracy: 88.1%, Avg loss: 0.428140 \n",
      "\n",
      "batch 4, loss: 0.444243, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 88.3%, Avg loss: 0.424110 \n",
      "\n",
      "batch 5, loss: 0.405563, accuracy: 86.7%\n",
      "Test Error: \n",
      "Accuracy: 88.8%, Avg loss: 0.423414 \n",
      "\n",
      "batch 6, loss: 0.385696, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 88.8%, Avg loss: 0.419822 \n",
      "\n",
      "batch 7, loss: 0.425913, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 88.9%, Avg loss: 0.418243 \n",
      "\n",
      "batch 8, loss: 0.438183, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 89.3%, Avg loss: 0.416513 \n",
      "\n",
      "batch 9, loss: 0.482980, accuracy: 85.2%\n",
      "Test Error: \n",
      "Accuracy: 88.9%, Avg loss: 0.417589 \n",
      "\n",
      "batch 10, loss: 0.423912, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 88.7%, Avg loss: 0.419822 \n",
      "\n",
      "batch 11, loss: 0.504442, accuracy: 85.9%\n",
      "Test Error: \n",
      "Accuracy: 88.8%, Avg loss: 0.416482 \n",
      "\n",
      "batch 12, loss: 0.364164, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 88.8%, Avg loss: 0.414159 \n",
      "\n",
      "batch 13, loss: 0.361525, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 88.5%, Avg loss: 0.413638 \n",
      "\n",
      "batch 14, loss: 0.447499, accuracy: 85.2%\n",
      "Test Error: \n",
      "Accuracy: 88.4%, Avg loss: 0.415656 \n",
      "\n",
      "batch 15, loss: 0.444721, accuracy: 86.7%\n",
      "Test Error: \n",
      "Accuracy: 88.6%, Avg loss: 0.415647 \n",
      "\n",
      "batch 16, loss: 0.434389, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 88.6%, Avg loss: 0.416041 \n",
      "\n",
      "batch 17, loss: 0.442457, accuracy: 84.0%\n",
      "Test Error: \n",
      "Accuracy: 88.8%, Avg loss: 0.417075 \n",
      "\n",
      "batch 18, loss: 0.410303, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 88.6%, Avg loss: 0.416313 \n",
      "\n",
      "batch 19, loss: 0.397139, accuracy: 87.1%\n",
      "Test Error: \n",
      "Accuracy: 88.4%, Avg loss: 0.415637 \n",
      "\n",
      "batch 20, loss: 0.471558, accuracy: 86.3%\n",
      "Test Error: \n",
      "Accuracy: 88.6%, Avg loss: 0.413180 \n",
      "\n",
      "batch 21, loss: 0.376891, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 88.8%, Avg loss: 0.410147 \n",
      "\n",
      "batch 22, loss: 0.372239, accuracy: 87.1%\n",
      "Test Error: \n",
      "Accuracy: 88.8%, Avg loss: 0.410527 \n",
      "\n",
      "batch 23, loss: 0.410967, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 89.0%, Avg loss: 0.407810 \n",
      "\n",
      "batch 24, loss: 0.480357, accuracy: 84.8%\n",
      "Test Error: \n",
      "Accuracy: 89.1%, Avg loss: 0.406187 \n",
      "\n",
      "batch 25, loss: 0.421555, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 89.3%, Avg loss: 0.401347 \n",
      "\n",
      "batch 26, loss: 0.402134, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 89.0%, Avg loss: 0.400727 \n",
      "\n",
      "batch 27, loss: 0.424094, accuracy: 85.2%\n",
      "Test Error: \n",
      "Accuracy: 89.0%, Avg loss: 0.398180 \n",
      "\n",
      "batch 28, loss: 0.390524, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 88.8%, Avg loss: 0.398103 \n",
      "\n",
      "batch 29, loss: 0.433694, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 88.9%, Avg loss: 0.396569 \n",
      "\n",
      "batch 30, loss: 0.339442, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 88.9%, Avg loss: 0.398063 \n",
      "\n",
      "batch 31, loss: 0.535124, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 89.0%, Avg loss: 0.396864 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "batch 0, loss: 0.409031, accuracy: 87.1%\n",
      "Test Error: \n",
      "Accuracy: 88.9%, Avg loss: 0.397591 \n",
      "\n",
      "batch 1, loss: 0.358727, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 89.0%, Avg loss: 0.395451 \n",
      "\n",
      "batch 2, loss: 0.389591, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 89.5%, Avg loss: 0.396266 \n",
      "\n",
      "batch 3, loss: 0.394203, accuracy: 88.3%\n",
      "Test Error: \n",
      "Accuracy: 89.2%, Avg loss: 0.396689 \n",
      "\n",
      "batch 4, loss: 0.412085, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 89.1%, Avg loss: 0.394983 \n",
      "\n",
      "batch 5, loss: 0.348516, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 88.9%, Avg loss: 0.395513 \n",
      "\n",
      "batch 6, loss: 0.365866, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 89.0%, Avg loss: 0.395879 \n",
      "\n",
      "batch 7, loss: 0.420834, accuracy: 85.9%\n",
      "Test Error: \n",
      "Accuracy: 89.0%, Avg loss: 0.395685 \n",
      "\n",
      "batch 8, loss: 0.397304, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 88.8%, Avg loss: 0.391891 \n",
      "\n",
      "batch 9, loss: 0.490928, accuracy: 84.0%\n",
      "Test Error: \n",
      "Accuracy: 89.0%, Avg loss: 0.391666 \n",
      "\n",
      "batch 10, loss: 0.414258, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 89.5%, Avg loss: 0.386508 \n",
      "\n",
      "batch 11, loss: 0.394740, accuracy: 88.3%\n",
      "Test Error: \n",
      "Accuracy: 89.5%, Avg loss: 0.386283 \n",
      "\n",
      "batch 12, loss: 0.331446, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 89.6%, Avg loss: 0.384558 \n",
      "\n",
      "batch 13, loss: 0.388651, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 89.8%, Avg loss: 0.386489 \n",
      "\n",
      "batch 14, loss: 0.440039, accuracy: 86.3%\n",
      "Test Error: \n",
      "Accuracy: 89.6%, Avg loss: 0.384074 \n",
      "\n",
      "batch 15, loss: 0.396298, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 89.2%, Avg loss: 0.381926 \n",
      "\n",
      "batch 16, loss: 0.389758, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 89.4%, Avg loss: 0.379675 \n",
      "\n",
      "batch 17, loss: 0.340415, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 89.1%, Avg loss: 0.378899 \n",
      "\n",
      "batch 18, loss: 0.405495, accuracy: 88.3%\n",
      "Test Error: \n",
      "Accuracy: 89.3%, Avg loss: 0.378182 \n",
      "\n",
      "batch 19, loss: 0.458760, accuracy: 86.3%\n",
      "Test Error: \n",
      "Accuracy: 89.3%, Avg loss: 0.376137 \n",
      "\n",
      "batch 20, loss: 0.414668, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 89.5%, Avg loss: 0.373097 \n",
      "\n",
      "batch 21, loss: 0.380913, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 89.7%, Avg loss: 0.369277 \n",
      "\n",
      "batch 22, loss: 0.353045, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 89.6%, Avg loss: 0.368829 \n",
      "\n",
      "batch 23, loss: 0.349670, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 89.6%, Avg loss: 0.369059 \n",
      "\n",
      "batch 24, loss: 0.332008, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 89.7%, Avg loss: 0.366323 \n",
      "\n",
      "batch 25, loss: 0.342647, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 90.0%, Avg loss: 0.365293 \n",
      "\n",
      "batch 26, loss: 0.348200, accuracy: 87.1%\n",
      "Test Error: \n",
      "Accuracy: 89.9%, Avg loss: 0.363252 \n",
      "\n",
      "batch 27, loss: 0.378196, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 89.8%, Avg loss: 0.362478 \n",
      "\n",
      "batch 28, loss: 0.371114, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 90.1%, Avg loss: 0.363919 \n",
      "\n",
      "batch 29, loss: 0.394464, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 89.7%, Avg loss: 0.363228 \n",
      "\n",
      "batch 30, loss: 0.326027, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 89.8%, Avg loss: 0.360896 \n",
      "\n",
      "batch 31, loss: 0.337480, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 90.0%, Avg loss: 0.357435 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "batch 0, loss: 0.427537, accuracy: 86.3%\n",
      "Test Error: \n",
      "Accuracy: 90.3%, Avg loss: 0.356494 \n",
      "\n",
      "batch 1, loss: 0.406225, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 90.0%, Avg loss: 0.358616 \n",
      "\n",
      "batch 2, loss: 0.351489, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 90.1%, Avg loss: 0.358468 \n",
      "\n",
      "batch 3, loss: 0.305969, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 90.0%, Avg loss: 0.357887 \n",
      "\n",
      "batch 4, loss: 0.372750, accuracy: 86.7%\n",
      "Test Error: \n",
      "Accuracy: 90.2%, Avg loss: 0.357129 \n",
      "\n",
      "batch 5, loss: 0.305595, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 90.0%, Avg loss: 0.355202 \n",
      "\n",
      "batch 6, loss: 0.294224, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 89.9%, Avg loss: 0.356264 \n",
      "\n",
      "batch 7, loss: 0.382265, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 89.9%, Avg loss: 0.357852 \n",
      "\n",
      "batch 8, loss: 0.378386, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 90.0%, Avg loss: 0.354072 \n",
      "\n",
      "batch 9, loss: 0.381010, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 90.0%, Avg loss: 0.351548 \n",
      "\n",
      "batch 10, loss: 0.385862, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 90.0%, Avg loss: 0.352229 \n",
      "\n",
      "batch 11, loss: 0.356991, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 90.2%, Avg loss: 0.348730 \n",
      "\n",
      "batch 12, loss: 0.382986, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 90.6%, Avg loss: 0.346684 \n",
      "\n",
      "batch 13, loss: 0.357138, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 90.3%, Avg loss: 0.344887 \n",
      "\n",
      "batch 14, loss: 0.355899, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 90.3%, Avg loss: 0.344123 \n",
      "\n",
      "batch 15, loss: 0.329759, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 90.2%, Avg loss: 0.345550 \n",
      "\n",
      "batch 16, loss: 0.305993, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 90.1%, Avg loss: 0.345439 \n",
      "\n",
      "batch 17, loss: 0.343820, accuracy: 88.3%\n",
      "Test Error: \n",
      "Accuracy: 90.0%, Avg loss: 0.344173 \n",
      "\n",
      "batch 18, loss: 0.374186, accuracy: 86.7%\n",
      "Test Error: \n",
      "Accuracy: 90.1%, Avg loss: 0.344485 \n",
      "\n",
      "batch 19, loss: 0.302090, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 90.2%, Avg loss: 0.344043 \n",
      "\n",
      "batch 20, loss: 0.360515, accuracy: 86.7%\n",
      "Test Error: \n",
      "Accuracy: 90.3%, Avg loss: 0.340428 \n",
      "\n",
      "batch 21, loss: 0.374150, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 90.3%, Avg loss: 0.339365 \n",
      "\n",
      "batch 22, loss: 0.307077, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 90.7%, Avg loss: 0.337975 \n",
      "\n",
      "batch 23, loss: 0.290042, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 90.9%, Avg loss: 0.334561 \n",
      "\n",
      "batch 24, loss: 0.385454, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 90.7%, Avg loss: 0.334663 \n",
      "\n",
      "batch 25, loss: 0.317069, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.334806 \n",
      "\n",
      "batch 26, loss: 0.261562, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.332127 \n",
      "\n",
      "batch 27, loss: 0.328260, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 91.0%, Avg loss: 0.329913 \n",
      "\n",
      "batch 28, loss: 0.324972, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 91.3%, Avg loss: 0.328651 \n",
      "\n",
      "batch 29, loss: 0.300447, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.3%, Avg loss: 0.326987 \n",
      "\n",
      "batch 30, loss: 0.340328, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 91.3%, Avg loss: 0.325872 \n",
      "\n",
      "batch 31, loss: 0.260357, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 91.6%, Avg loss: 0.324356 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "batch 0, loss: 0.289082, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.325074 \n",
      "\n",
      "batch 1, loss: 0.265333, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 91.7%, Avg loss: 0.323694 \n",
      "\n",
      "batch 2, loss: 0.323860, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 91.8%, Avg loss: 0.319631 \n",
      "\n",
      "batch 3, loss: 0.335482, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 91.6%, Avg loss: 0.320350 \n",
      "\n",
      "batch 4, loss: 0.357407, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.317477 \n",
      "\n",
      "batch 5, loss: 0.315854, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.3%, Avg loss: 0.318634 \n",
      "\n",
      "batch 6, loss: 0.252335, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.319377 \n",
      "\n",
      "batch 7, loss: 0.320815, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.4%, Avg loss: 0.318375 \n",
      "\n",
      "batch 8, loss: 0.309172, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.315616 \n",
      "\n",
      "batch 9, loss: 0.400809, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.315889 \n",
      "\n",
      "batch 10, loss: 0.326947, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 91.4%, Avg loss: 0.317960 \n",
      "\n",
      "batch 11, loss: 0.365596, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 91.2%, Avg loss: 0.319889 \n",
      "\n",
      "batch 12, loss: 0.295760, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 91.1%, Avg loss: 0.320275 \n",
      "\n",
      "batch 13, loss: 0.254998, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.322274 \n",
      "\n",
      "batch 14, loss: 0.378982, accuracy: 88.7%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.321078 \n",
      "\n",
      "batch 15, loss: 0.317580, accuracy: 91.4%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.319894 \n",
      "\n",
      "batch 16, loss: 0.312358, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 90.6%, Avg loss: 0.321049 \n",
      "\n",
      "batch 17, loss: 0.318463, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 90.7%, Avg loss: 0.321114 \n",
      "\n",
      "batch 18, loss: 0.282424, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.321804 \n",
      "\n",
      "batch 19, loss: 0.313874, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 90.5%, Avg loss: 0.322183 \n",
      "\n",
      "batch 20, loss: 0.374766, accuracy: 87.1%\n",
      "Test Error: \n",
      "Accuracy: 91.0%, Avg loss: 0.317072 \n",
      "\n",
      "batch 21, loss: 0.354284, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 91.2%, Avg loss: 0.312184 \n",
      "\n",
      "batch 22, loss: 0.345973, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 91.2%, Avg loss: 0.310390 \n",
      "\n",
      "batch 23, loss: 0.323146, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.305769 \n",
      "\n",
      "batch 24, loss: 0.312700, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 91.3%, Avg loss: 0.302366 \n",
      "\n",
      "batch 25, loss: 0.312954, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 91.3%, Avg loss: 0.303061 \n",
      "\n",
      "batch 26, loss: 0.299779, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 91.3%, Avg loss: 0.304686 \n",
      "\n",
      "batch 27, loss: 0.358793, accuracy: 87.5%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.302153 \n",
      "\n",
      "batch 28, loss: 0.319634, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.301739 \n",
      "\n",
      "batch 29, loss: 0.286619, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.1%, Avg loss: 0.300377 \n",
      "\n",
      "batch 30, loss: 0.276589, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.302021 \n",
      "\n",
      "batch 31, loss: 0.291192, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 91.1%, Avg loss: 0.301093 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "batch 0, loss: 0.292309, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.1%, Avg loss: 0.301380 \n",
      "\n",
      "batch 1, loss: 0.305542, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.302730 \n",
      "\n",
      "batch 2, loss: 0.301167, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.303529 \n",
      "\n",
      "batch 3, loss: 0.250244, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 90.6%, Avg loss: 0.307059 \n",
      "\n",
      "batch 4, loss: 0.338278, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 90.9%, Avg loss: 0.306755 \n",
      "\n",
      "batch 5, loss: 0.297349, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 91.0%, Avg loss: 0.307837 \n",
      "\n",
      "batch 6, loss: 0.235245, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.307058 \n",
      "\n",
      "batch 7, loss: 0.360684, accuracy: 87.1%\n",
      "Test Error: \n",
      "Accuracy: 91.0%, Avg loss: 0.305769 \n",
      "\n",
      "batch 8, loss: 0.297838, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 91.0%, Avg loss: 0.301244 \n",
      "\n",
      "batch 9, loss: 0.285306, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 90.8%, Avg loss: 0.299744 \n",
      "\n",
      "batch 10, loss: 0.302333, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 90.9%, Avg loss: 0.299007 \n",
      "\n",
      "batch 11, loss: 0.293137, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 91.0%, Avg loss: 0.298477 \n",
      "\n",
      "batch 12, loss: 0.242409, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.294321 \n",
      "\n",
      "batch 13, loss: 0.284553, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 91.3%, Avg loss: 0.295342 \n",
      "\n",
      "batch 14, loss: 0.276670, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.291613 \n",
      "\n",
      "batch 15, loss: 0.272185, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 91.7%, Avg loss: 0.289979 \n",
      "\n",
      "batch 16, loss: 0.312397, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.6%, Avg loss: 0.291021 \n",
      "\n",
      "batch 17, loss: 0.286986, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.5%, Avg loss: 0.289773 \n",
      "\n",
      "batch 18, loss: 0.275872, accuracy: 91.4%\n",
      "Test Error: \n",
      "Accuracy: 91.6%, Avg loss: 0.287374 \n",
      "\n",
      "batch 19, loss: 0.239601, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 91.8%, Avg loss: 0.286202 \n",
      "\n",
      "batch 20, loss: 0.253730, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 91.6%, Avg loss: 0.286704 \n",
      "\n",
      "batch 21, loss: 0.294037, accuracy: 89.5%\n",
      "Test Error: \n",
      "Accuracy: 91.2%, Avg loss: 0.287879 \n",
      "\n",
      "batch 22, loss: 0.306696, accuracy: 91.4%\n",
      "Test Error: \n",
      "Accuracy: 91.2%, Avg loss: 0.286620 \n",
      "\n",
      "batch 23, loss: 0.315988, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 91.3%, Avg loss: 0.284948 \n",
      "\n",
      "batch 24, loss: 0.240258, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 91.8%, Avg loss: 0.283317 \n",
      "\n",
      "batch 25, loss: 0.303985, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 92.0%, Avg loss: 0.282544 \n",
      "\n",
      "batch 26, loss: 0.308324, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 92.2%, Avg loss: 0.282034 \n",
      "\n",
      "batch 27, loss: 0.287442, accuracy: 91.4%\n",
      "Test Error: \n",
      "Accuracy: 92.3%, Avg loss: 0.279126 \n",
      "\n",
      "batch 28, loss: 0.347816, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 92.2%, Avg loss: 0.275079 \n",
      "\n",
      "batch 29, loss: 0.258848, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 92.1%, Avg loss: 0.274981 \n",
      "\n",
      "batch 30, loss: 0.252348, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 92.3%, Avg loss: 0.273778 \n",
      "\n",
      "batch 31, loss: 0.226400, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.273537 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "batch 0, loss: 0.232768, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.272831 \n",
      "\n",
      "batch 1, loss: 0.279181, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 92.6%, Avg loss: 0.273140 \n",
      "\n",
      "batch 2, loss: 0.259359, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.270841 \n",
      "\n",
      "batch 3, loss: 0.268672, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 92.3%, Avg loss: 0.270534 \n",
      "\n",
      "batch 4, loss: 0.263728, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 92.3%, Avg loss: 0.271242 \n",
      "\n",
      "batch 5, loss: 0.278981, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.267969 \n",
      "\n",
      "batch 6, loss: 0.285655, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.269464 \n",
      "\n",
      "batch 7, loss: 0.329479, accuracy: 87.9%\n",
      "Test Error: \n",
      "Accuracy: 92.3%, Avg loss: 0.268825 \n",
      "\n",
      "batch 8, loss: 0.189407, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 92.4%, Avg loss: 0.267373 \n",
      "\n",
      "batch 9, loss: 0.230595, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.265839 \n",
      "\n",
      "batch 10, loss: 0.323706, accuracy: 89.8%\n",
      "Test Error: \n",
      "Accuracy: 92.4%, Avg loss: 0.266682 \n",
      "\n",
      "batch 11, loss: 0.238375, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.264601 \n",
      "\n",
      "batch 12, loss: 0.217591, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.262016 \n",
      "\n",
      "batch 13, loss: 0.364559, accuracy: 88.3%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.260546 \n",
      "\n",
      "batch 14, loss: 0.197854, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.261934 \n",
      "\n",
      "batch 15, loss: 0.273586, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 92.3%, Avg loss: 0.262491 \n",
      "\n",
      "batch 16, loss: 0.246934, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.263384 \n",
      "\n",
      "batch 17, loss: 0.233254, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.3%, Avg loss: 0.263212 \n",
      "\n",
      "batch 18, loss: 0.258450, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.0%, Avg loss: 0.261488 \n",
      "\n",
      "batch 19, loss: 0.177956, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 91.8%, Avg loss: 0.263467 \n",
      "\n",
      "batch 20, loss: 0.206800, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 92.0%, Avg loss: 0.265262 \n",
      "\n",
      "batch 21, loss: 0.265065, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 92.0%, Avg loss: 0.263474 \n",
      "\n",
      "batch 22, loss: 0.268167, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 92.4%, Avg loss: 0.259823 \n",
      "\n",
      "batch 23, loss: 0.232027, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.256674 \n",
      "\n",
      "batch 24, loss: 0.235089, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.256963 \n",
      "\n",
      "batch 25, loss: 0.257357, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.253009 \n",
      "\n",
      "batch 26, loss: 0.221372, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.253356 \n",
      "\n",
      "batch 27, loss: 0.263447, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 92.9%, Avg loss: 0.252147 \n",
      "\n",
      "batch 28, loss: 0.205885, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.253212 \n",
      "\n",
      "batch 29, loss: 0.203022, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.250789 \n",
      "\n",
      "batch 30, loss: 0.225661, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 92.6%, Avg loss: 0.249589 \n",
      "\n",
      "batch 31, loss: 0.253865, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 92.6%, Avg loss: 0.247593 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "batch 0, loss: 0.224949, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.248386 \n",
      "\n",
      "batch 1, loss: 0.212060, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 92.6%, Avg loss: 0.249658 \n",
      "\n",
      "batch 2, loss: 0.216417, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.247575 \n",
      "\n",
      "batch 3, loss: 0.314514, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.248477 \n",
      "\n",
      "batch 4, loss: 0.217257, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.250729 \n",
      "\n",
      "batch 5, loss: 0.202635, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.250555 \n",
      "\n",
      "batch 6, loss: 0.229056, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.250784 \n",
      "\n",
      "batch 7, loss: 0.200850, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.249869 \n",
      "\n",
      "batch 8, loss: 0.242963, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.249873 \n",
      "\n",
      "batch 9, loss: 0.219085, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.249203 \n",
      "\n",
      "batch 10, loss: 0.229968, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.249174 \n",
      "\n",
      "batch 11, loss: 0.234972, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.248500 \n",
      "\n",
      "batch 12, loss: 0.227984, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.248214 \n",
      "\n",
      "batch 13, loss: 0.203173, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.249617 \n",
      "\n",
      "batch 14, loss: 0.278257, accuracy: 91.0%\n",
      "Test Error: \n",
      "Accuracy: 92.9%, Avg loss: 0.250104 \n",
      "\n",
      "batch 15, loss: 0.193216, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.249047 \n",
      "\n",
      "batch 16, loss: 0.199309, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.246909 \n",
      "\n",
      "batch 17, loss: 0.220429, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 92.9%, Avg loss: 0.247581 \n",
      "\n",
      "batch 18, loss: 0.217798, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.248259 \n",
      "\n",
      "batch 19, loss: 0.299781, accuracy: 91.4%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.244399 \n",
      "\n",
      "batch 20, loss: 0.243614, accuracy: 91.4%\n",
      "Test Error: \n",
      "Accuracy: 92.4%, Avg loss: 0.242555 \n",
      "\n",
      "batch 21, loss: 0.218197, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.240357 \n",
      "\n",
      "batch 22, loss: 0.238726, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.240230 \n",
      "\n",
      "batch 23, loss: 0.194870, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.239134 \n",
      "\n",
      "batch 24, loss: 0.189401, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 92.2%, Avg loss: 0.238149 \n",
      "\n",
      "batch 25, loss: 0.251496, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 92.1%, Avg loss: 0.238949 \n",
      "\n",
      "batch 26, loss: 0.252625, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.238446 \n",
      "\n",
      "batch 27, loss: 0.238147, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 92.4%, Avg loss: 0.240120 \n",
      "\n",
      "batch 28, loss: 0.280742, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.240791 \n",
      "\n",
      "batch 29, loss: 0.240550, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 92.4%, Avg loss: 0.237763 \n",
      "\n",
      "batch 30, loss: 0.228323, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.236580 \n",
      "\n",
      "batch 31, loss: 0.208488, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.234768 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "batch 0, loss: 0.194370, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.237027 \n",
      "\n",
      "batch 1, loss: 0.220929, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.237032 \n",
      "\n",
      "batch 2, loss: 0.196856, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.235945 \n",
      "\n",
      "batch 3, loss: 0.192098, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.234166 \n",
      "\n",
      "batch 4, loss: 0.221242, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.235617 \n",
      "\n",
      "batch 5, loss: 0.201617, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.236000 \n",
      "\n",
      "batch 6, loss: 0.158448, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.236127 \n",
      "\n",
      "batch 7, loss: 0.264464, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 92.9%, Avg loss: 0.235622 \n",
      "\n",
      "batch 8, loss: 0.211347, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.235341 \n",
      "\n",
      "batch 9, loss: 0.238205, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.233923 \n",
      "\n",
      "batch 10, loss: 0.178500, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.233917 \n",
      "\n",
      "batch 11, loss: 0.235087, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.6%, Avg loss: 0.231930 \n",
      "\n",
      "batch 12, loss: 0.264177, accuracy: 91.4%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.232203 \n",
      "\n",
      "batch 13, loss: 0.262049, accuracy: 90.2%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.228234 \n",
      "\n",
      "batch 14, loss: 0.253104, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.226674 \n",
      "\n",
      "batch 15, loss: 0.236970, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.224997 \n",
      "\n",
      "batch 16, loss: 0.217446, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.226068 \n",
      "\n",
      "batch 17, loss: 0.188753, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 93.1%, Avg loss: 0.223484 \n",
      "\n",
      "batch 18, loss: 0.206619, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 93.3%, Avg loss: 0.219611 \n",
      "\n",
      "batch 19, loss: 0.196034, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.219524 \n",
      "\n",
      "batch 20, loss: 0.165571, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 93.3%, Avg loss: 0.218322 \n",
      "\n",
      "batch 21, loss: 0.223388, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.218410 \n",
      "\n",
      "batch 22, loss: 0.193379, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 93.1%, Avg loss: 0.217962 \n",
      "\n",
      "batch 23, loss: 0.174155, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.218127 \n",
      "\n",
      "batch 24, loss: 0.210484, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.218554 \n",
      "\n",
      "batch 25, loss: 0.279559, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.218499 \n",
      "\n",
      "batch 26, loss: 0.174942, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.218351 \n",
      "\n",
      "batch 27, loss: 0.244124, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.219155 \n",
      "\n",
      "batch 28, loss: 0.221524, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.219218 \n",
      "\n",
      "batch 29, loss: 0.174065, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 93.3%, Avg loss: 0.216739 \n",
      "\n",
      "batch 30, loss: 0.197822, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 93.3%, Avg loss: 0.217588 \n",
      "\n",
      "batch 31, loss: 0.235636, accuracy: 89.1%\n",
      "Test Error: \n",
      "Accuracy: 93.3%, Avg loss: 0.217119 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "batch 0, loss: 0.209239, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 93.3%, Avg loss: 0.216578 \n",
      "\n",
      "batch 1, loss: 0.173850, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 93.1%, Avg loss: 0.217729 \n",
      "\n",
      "batch 2, loss: 0.181311, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 93.3%, Avg loss: 0.217312 \n",
      "\n",
      "batch 3, loss: 0.213142, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.217010 \n",
      "\n",
      "batch 4, loss: 0.162206, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 92.9%, Avg loss: 0.216870 \n",
      "\n",
      "batch 5, loss: 0.180399, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.215923 \n",
      "\n",
      "batch 6, loss: 0.232392, accuracy: 91.4%\n",
      "Test Error: \n",
      "Accuracy: 93.2%, Avg loss: 0.214188 \n",
      "\n",
      "batch 7, loss: 0.213713, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 93.1%, Avg loss: 0.214481 \n",
      "\n",
      "batch 8, loss: 0.216514, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 92.9%, Avg loss: 0.215708 \n",
      "\n",
      "batch 9, loss: 0.216788, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.214616 \n",
      "\n",
      "batch 10, loss: 0.238260, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.216746 \n",
      "\n",
      "batch 11, loss: 0.202531, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.215159 \n",
      "\n",
      "batch 12, loss: 0.191913, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 92.6%, Avg loss: 0.216582 \n",
      "\n",
      "batch 13, loss: 0.271669, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.216436 \n",
      "\n",
      "batch 14, loss: 0.189767, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.215655 \n",
      "\n",
      "batch 15, loss: 0.192301, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.214005 \n",
      "\n",
      "batch 16, loss: 0.198325, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.214213 \n",
      "\n",
      "batch 17, loss: 0.203801, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 92.5%, Avg loss: 0.215704 \n",
      "\n",
      "batch 18, loss: 0.228699, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 92.6%, Avg loss: 0.214140 \n",
      "\n",
      "batch 19, loss: 0.201450, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 92.7%, Avg loss: 0.210739 \n",
      "\n",
      "batch 20, loss: 0.202060, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 92.8%, Avg loss: 0.209312 \n",
      "\n",
      "batch 21, loss: 0.154583, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 93.0%, Avg loss: 0.208600 \n",
      "\n",
      "batch 22, loss: 0.159211, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 93.1%, Avg loss: 0.208660 \n",
      "\n",
      "batch 23, loss: 0.194885, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 93.3%, Avg loss: 0.207730 \n",
      "\n",
      "batch 24, loss: 0.205240, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 93.4%, Avg loss: 0.206789 \n",
      "\n",
      "batch 25, loss: 0.180819, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 93.6%, Avg loss: 0.204639 \n",
      "\n",
      "batch 26, loss: 0.231362, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.202512 \n",
      "\n",
      "batch 27, loss: 0.146304, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 93.8%, Avg loss: 0.204031 \n",
      "\n",
      "batch 28, loss: 0.202397, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 93.6%, Avg loss: 0.204330 \n",
      "\n",
      "batch 29, loss: 0.172016, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 93.5%, Avg loss: 0.204673 \n",
      "\n",
      "batch 30, loss: 0.205876, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 93.6%, Avg loss: 0.201506 \n",
      "\n",
      "batch 31, loss: 0.134754, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 93.7%, Avg loss: 0.200881 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "batch 0, loss: 0.188389, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.199646 \n",
      "\n",
      "batch 1, loss: 0.154356, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.199794 \n",
      "\n",
      "batch 2, loss: 0.176840, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 94.1%, Avg loss: 0.196944 \n",
      "\n",
      "batch 3, loss: 0.183562, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.196279 \n",
      "\n",
      "batch 4, loss: 0.183438, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.197378 \n",
      "\n",
      "batch 5, loss: 0.192697, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 94.1%, Avg loss: 0.195346 \n",
      "\n",
      "batch 6, loss: 0.166916, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 94.1%, Avg loss: 0.194419 \n",
      "\n",
      "batch 7, loss: 0.203901, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.196482 \n",
      "\n",
      "batch 8, loss: 0.153989, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.195791 \n",
      "\n",
      "batch 9, loss: 0.180994, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.194653 \n",
      "\n",
      "batch 10, loss: 0.170752, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.192989 \n",
      "\n",
      "batch 11, loss: 0.245771, accuracy: 91.8%\n",
      "Test Error: \n",
      "Accuracy: 94.1%, Avg loss: 0.191473 \n",
      "\n",
      "batch 12, loss: 0.201937, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.194997 \n",
      "\n",
      "batch 13, loss: 0.219826, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.194221 \n",
      "\n",
      "batch 14, loss: 0.142163, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 94.4%, Avg loss: 0.194407 \n",
      "\n",
      "batch 15, loss: 0.237696, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.192591 \n",
      "\n",
      "batch 16, loss: 0.193700, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 94.4%, Avg loss: 0.190735 \n",
      "\n",
      "batch 17, loss: 0.218361, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.188776 \n",
      "\n",
      "batch 18, loss: 0.175189, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 94.4%, Avg loss: 0.187814 \n",
      "\n",
      "batch 19, loss: 0.178842, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.190531 \n",
      "\n",
      "batch 20, loss: 0.216667, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 94.5%, Avg loss: 0.190045 \n",
      "\n",
      "batch 21, loss: 0.181827, accuracy: 92.6%\n",
      "Test Error: \n",
      "Accuracy: 94.5%, Avg loss: 0.190851 \n",
      "\n",
      "batch 22, loss: 0.173691, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 94.4%, Avg loss: 0.191737 \n",
      "\n",
      "batch 23, loss: 0.153336, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.194437 \n",
      "\n",
      "batch 24, loss: 0.227865, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.193105 \n",
      "\n",
      "batch 25, loss: 0.198178, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.194837 \n",
      "\n",
      "batch 26, loss: 0.138914, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.193275 \n",
      "\n",
      "batch 27, loss: 0.214756, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.191537 \n",
      "\n",
      "batch 28, loss: 0.138591, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.191915 \n",
      "\n",
      "batch 29, loss: 0.221427, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.189864 \n",
      "\n",
      "batch 30, loss: 0.142664, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.188466 \n",
      "\n",
      "batch 31, loss: 0.209929, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.189767 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "batch 0, loss: 0.155203, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.188364 \n",
      "\n",
      "batch 1, loss: 0.130092, accuracy: 97.3%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.188305 \n",
      "\n",
      "batch 2, loss: 0.219355, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 94.0%, Avg loss: 0.189521 \n",
      "\n",
      "batch 3, loss: 0.248033, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.189657 \n",
      "\n",
      "batch 4, loss: 0.177317, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 94.4%, Avg loss: 0.186422 \n",
      "\n",
      "batch 5, loss: 0.190669, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 94.5%, Avg loss: 0.185995 \n",
      "\n",
      "batch 6, loss: 0.140656, accuracy: 97.3%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.186476 \n",
      "\n",
      "batch 7, loss: 0.181518, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.185629 \n",
      "\n",
      "batch 8, loss: 0.173429, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 94.4%, Avg loss: 0.184119 \n",
      "\n",
      "batch 9, loss: 0.227412, accuracy: 91.4%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.183883 \n",
      "\n",
      "batch 10, loss: 0.172772, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.184125 \n",
      "\n",
      "batch 11, loss: 0.140357, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.183756 \n",
      "\n",
      "batch 12, loss: 0.159286, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.182518 \n",
      "\n",
      "batch 13, loss: 0.149879, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.184187 \n",
      "\n",
      "batch 14, loss: 0.145744, accuracy: 97.3%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.183468 \n",
      "\n",
      "batch 15, loss: 0.218862, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.183036 \n",
      "\n",
      "batch 16, loss: 0.137521, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 94.2%, Avg loss: 0.183999 \n",
      "\n",
      "batch 17, loss: 0.181843, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 94.3%, Avg loss: 0.182302 \n",
      "\n",
      "batch 18, loss: 0.192119, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 94.5%, Avg loss: 0.180736 \n",
      "\n",
      "batch 19, loss: 0.209529, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 94.6%, Avg loss: 0.179074 \n",
      "\n",
      "batch 20, loss: 0.119764, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 94.5%, Avg loss: 0.177914 \n",
      "\n",
      "batch 21, loss: 0.138120, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 94.8%, Avg loss: 0.176844 \n",
      "\n",
      "batch 22, loss: 0.149175, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.173217 \n",
      "\n",
      "batch 23, loss: 0.203178, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 95.1%, Avg loss: 0.170968 \n",
      "\n",
      "batch 24, loss: 0.150187, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.170935 \n",
      "\n",
      "batch 25, loss: 0.186927, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.170323 \n",
      "\n",
      "batch 26, loss: 0.175547, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.168946 \n",
      "\n",
      "batch 27, loss: 0.154770, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.169877 \n",
      "\n",
      "batch 28, loss: 0.177500, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.170355 \n",
      "\n",
      "batch 29, loss: 0.160955, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.171373 \n",
      "\n",
      "batch 30, loss: 0.179201, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.170338 \n",
      "\n",
      "batch 31, loss: 0.135310, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.171282 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "batch 0, loss: 0.144602, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.1%, Avg loss: 0.168903 \n",
      "\n",
      "batch 1, loss: 0.115090, accuracy: 98.0%\n",
      "Test Error: \n",
      "Accuracy: 95.1%, Avg loss: 0.168330 \n",
      "\n",
      "batch 2, loss: 0.124173, accuracy: 97.3%\n",
      "Test Error: \n",
      "Accuracy: 95.1%, Avg loss: 0.167143 \n",
      "\n",
      "batch 3, loss: 0.167378, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.167423 \n",
      "\n",
      "batch 4, loss: 0.205022, accuracy: 92.2%\n",
      "Test Error: \n",
      "Accuracy: 95.1%, Avg loss: 0.165818 \n",
      "\n",
      "batch 5, loss: 0.163279, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.162602 \n",
      "\n",
      "batch 6, loss: 0.156983, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.162272 \n",
      "\n",
      "batch 7, loss: 0.160958, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.160631 \n",
      "\n",
      "batch 8, loss: 0.138947, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 95.1%, Avg loss: 0.158504 \n",
      "\n",
      "batch 9, loss: 0.163841, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.159765 \n",
      "\n",
      "batch 10, loss: 0.184452, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.159875 \n",
      "\n",
      "batch 11, loss: 0.163325, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.160056 \n",
      "\n",
      "batch 12, loss: 0.182104, accuracy: 94.1%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.158941 \n",
      "\n",
      "batch 13, loss: 0.184668, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.159957 \n",
      "\n",
      "batch 14, loss: 0.158599, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.159596 \n",
      "\n",
      "batch 15, loss: 0.124256, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.160216 \n",
      "\n",
      "batch 16, loss: 0.147755, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.160477 \n",
      "\n",
      "batch 17, loss: 0.132213, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.160571 \n",
      "\n",
      "batch 18, loss: 0.150579, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.161844 \n",
      "\n",
      "batch 19, loss: 0.201669, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 95.0%, Avg loss: 0.160861 \n",
      "\n",
      "batch 20, loss: 0.157910, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.158928 \n",
      "\n",
      "batch 21, loss: 0.176543, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.1%, Avg loss: 0.158937 \n",
      "\n",
      "batch 22, loss: 0.155144, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 95.1%, Avg loss: 0.158386 \n",
      "\n",
      "batch 23, loss: 0.097478, accuracy: 98.4%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.157531 \n",
      "\n",
      "batch 24, loss: 0.123244, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.155394 \n",
      "\n",
      "batch 25, loss: 0.155512, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 95.4%, Avg loss: 0.156030 \n",
      "\n",
      "batch 26, loss: 0.173066, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.156646 \n",
      "\n",
      "batch 27, loss: 0.149575, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.156704 \n",
      "\n",
      "batch 28, loss: 0.164375, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.5%, Avg loss: 0.153800 \n",
      "\n",
      "batch 29, loss: 0.209394, accuracy: 90.6%\n",
      "Test Error: \n",
      "Accuracy: 95.6%, Avg loss: 0.154535 \n",
      "\n",
      "batch 30, loss: 0.121817, accuracy: 98.0%\n",
      "Test Error: \n",
      "Accuracy: 95.6%, Avg loss: 0.152017 \n",
      "\n",
      "batch 31, loss: 0.152477, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.7%, Avg loss: 0.151408 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "batch 0, loss: 0.141033, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 95.7%, Avg loss: 0.152037 \n",
      "\n",
      "batch 1, loss: 0.126749, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 95.8%, Avg loss: 0.152998 \n",
      "\n",
      "batch 2, loss: 0.163156, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.8%, Avg loss: 0.152492 \n",
      "\n",
      "batch 3, loss: 0.091694, accuracy: 98.0%\n",
      "Test Error: \n",
      "Accuracy: 95.7%, Avg loss: 0.151394 \n",
      "\n",
      "batch 4, loss: 0.152750, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.5%, Avg loss: 0.152440 \n",
      "\n",
      "batch 5, loss: 0.139247, accuracy: 97.3%\n",
      "Test Error: \n",
      "Accuracy: 95.5%, Avg loss: 0.152710 \n",
      "\n",
      "batch 6, loss: 0.164660, accuracy: 94.5%\n",
      "Test Error: \n",
      "Accuracy: 95.5%, Avg loss: 0.152771 \n",
      "\n",
      "batch 7, loss: 0.119445, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 95.7%, Avg loss: 0.152144 \n",
      "\n",
      "batch 8, loss: 0.139146, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 95.6%, Avg loss: 0.152054 \n",
      "\n",
      "batch 9, loss: 0.132664, accuracy: 97.3%\n",
      "Test Error: \n",
      "Accuracy: 95.7%, Avg loss: 0.152504 \n",
      "\n",
      "batch 10, loss: 0.199570, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 95.7%, Avg loss: 0.151969 \n",
      "\n",
      "batch 11, loss: 0.179718, accuracy: 93.4%\n",
      "Test Error: \n",
      "Accuracy: 95.6%, Avg loss: 0.152187 \n",
      "\n",
      "batch 12, loss: 0.125144, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 95.5%, Avg loss: 0.152833 \n",
      "\n",
      "batch 13, loss: 0.165336, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 95.7%, Avg loss: 0.152074 \n",
      "\n",
      "batch 14, loss: 0.141154, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.5%, Avg loss: 0.151120 \n",
      "\n",
      "batch 15, loss: 0.145143, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 95.5%, Avg loss: 0.150764 \n",
      "\n",
      "batch 16, loss: 0.136451, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.151325 \n",
      "\n",
      "batch 17, loss: 0.132654, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.150894 \n",
      "\n",
      "batch 18, loss: 0.135067, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.151431 \n",
      "\n",
      "batch 19, loss: 0.133040, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.150100 \n",
      "\n",
      "batch 20, loss: 0.131541, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.150681 \n",
      "\n",
      "batch 21, loss: 0.146648, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.1%, Avg loss: 0.152044 \n",
      "\n",
      "batch 22, loss: 0.136675, accuracy: 96.9%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.152323 \n",
      "\n",
      "batch 23, loss: 0.127637, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.151616 \n",
      "\n",
      "batch 24, loss: 0.110750, accuracy: 97.7%\n",
      "Test Error: \n",
      "Accuracy: 95.4%, Avg loss: 0.152015 \n",
      "\n",
      "batch 25, loss: 0.159511, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.2%, Avg loss: 0.152616 \n",
      "\n",
      "batch 26, loss: 0.132471, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 95.4%, Avg loss: 0.150950 \n",
      "\n",
      "batch 27, loss: 0.115293, accuracy: 97.7%\n",
      "Test Error: \n",
      "Accuracy: 95.4%, Avg loss: 0.150574 \n",
      "\n",
      "batch 28, loss: 0.183857, accuracy: 94.9%\n",
      "Test Error: \n",
      "Accuracy: 95.5%, Avg loss: 0.151473 \n",
      "\n",
      "batch 29, loss: 0.137730, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.152723 \n",
      "\n",
      "batch 30, loss: 0.137046, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 95.3%, Avg loss: 0.153110 \n",
      "\n",
      "batch 31, loss: 0.149178, accuracy: 93.8%\n",
      "Test Error: \n",
      "Accuracy: 95.5%, Avg loss: 0.151250 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "batch 0, loss: 0.134527, accuracy: 97.3%\n",
      "Test Error: \n",
      "Accuracy: 95.7%, Avg loss: 0.150973 \n",
      "\n",
      "batch 1, loss: 0.143044, accuracy: 95.7%\n",
      "Test Error: \n",
      "Accuracy: 95.8%, Avg loss: 0.150355 \n",
      "\n",
      "batch 2, loss: 0.130861, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 95.7%, Avg loss: 0.150431 \n",
      "\n",
      "batch 3, loss: 0.157489, accuracy: 95.3%\n",
      "Test Error: \n",
      "Accuracy: 95.9%, Avg loss: 0.148462 \n",
      "\n",
      "batch 4, loss: 0.176140, accuracy: 93.0%\n",
      "Test Error: \n",
      "Accuracy: 95.9%, Avg loss: 0.148025 \n",
      "\n",
      "batch 5, loss: 0.124982, accuracy: 96.5%\n",
      "Test Error: \n",
      "Accuracy: 95.9%, Avg loss: 0.146718 \n",
      "\n",
      "batch 6, loss: 0.139636, accuracy: 96.1%\n",
      "Test Error: \n",
      "Accuracy: 95.9%, Avg loss: 0.144324 \n",
      "\n",
      "batch 7, loss: 0.116725, accuracy: 97.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_17972/1730220787.py\", line 38, in train_snn\n",
      "    train_loop_snn(es_model, train_loader, val_loader, cross_entropy, device, run)\n",
      "  File \"/home/wyx/darwin_neuron/src/Training.py\", line 81, in train_loop_snn\n",
      "    val_stats = val_loop_snn(es_model, val_dataloader, loss_fn, device)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wyx/darwin_neuron/src/Training.py\", line 50, in val_loop_snn\n",
      "    for x, y in dataloader:\n",
      "                ^^^^^^^^^^\n",
      "  File \"/home/wyx/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wyx/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 757, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wyx/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wyx/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wyx/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 212, in collate\n",
      "    collate(samples, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/wyx/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wyx/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 272, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 38\u001b[0m, in \u001b[0;36mtrain_snn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m train_loop_snn(es_model, train_loader, val_loader, cross_entropy, device, run)\n",
      "File \u001b[0;32m~/darwin_neuron/src/Training.py:81\u001b[0m, in \u001b[0;36mtrain_loop_snn\u001b[0;34m(es_model, train_dataloader, val_dataloader, loss_fn, device, run)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m## validation loss and accuracy\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m val_stats \u001b[38;5;241m=\u001b[39m val_loop_snn(es_model, val_dataloader, loss_fn, device)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m## record keeping\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# train \u001b[39;00m\n",
      "File \u001b[0;32m~/darwin_neuron/src/Training.py:50\u001b[0m, in \u001b[0;36mval_loop_snn\u001b[0;34m(es_model, dataloader, loss_fn, device)\u001b[0m\n\u001b[1;32m     48\u001b[0m spike_count_per_neuron \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     51\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03mTake in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[38;5;241m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 212\u001b[0m         collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(batch, \u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m     38\u001b[0m             train_loop_snn(es_model, train_loader, val_loader, cross_entropy, device, run)\n\u001b[0;32m---> 40\u001b[0m train_snn()\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36mtrain_snn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msanity_check\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m config \u001b[38;5;241m=\u001b[39m { \u001b[38;5;66;03m# Dataset:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_input\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      8\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_output\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m10\u001b[39m,  \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     25\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregularization\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), wandb\u001b[38;5;241m.\u001b[39minit(entity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDarwinNeuron\u001b[39m\u001b[38;5;124m'\u001b[39m, project \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mES-Randman10\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mrun_name, config\u001b[38;5;241m=\u001b[39mconfig) \u001b[38;5;28;01mas\u001b[39;00m run:  \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# initialize Evolution Strategy instance\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     es_model \u001b[38;5;241m=\u001b[39m ESModel(RandmanSNN, run\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnb_input, run\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnb_hidden, run\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnb_output, \u001b[38;5;241m0.95\u001b[39m, sample_size\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnb_model_samples, param_std \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstd, Optimizer\u001b[38;5;241m=\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam, lr\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlr, device\u001b[38;5;241m=\u001b[39mdevice, mirror\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmirror)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# load dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:3719\u001b[0m, in \u001b[0;36mRun.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m   3717\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exception(exc_type, exc_val, exc_tb)\n\u001b[1;32m   3718\u001b[0m exit_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_raised \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 3719\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish(exit_code\u001b[38;5;241m=\u001b[39mexit_code)\n\u001b[1;32m   3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exception_raised\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:387\u001b[0m, in \u001b[0;36m_log_to_run.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attach_id\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wb_logging\u001b[38;5;241m.\u001b[39mlog_to_run(run_id):\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:2190\u001b[0m, in \u001b[0;36mRun._finish\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2184\u001b[0m \u001b[38;5;129m@_log_to_run\u001b[39m\n\u001b[1;32m   2185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_finish\u001b[39m(\n\u001b[1;32m   2186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2187\u001b[0m     exit_code: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2188\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2189\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinishing run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2190\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m telemetry\u001b[38;5;241m.\u001b[39mcontext(run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tel:\n\u001b[1;32m   2191\u001b[0m         tel\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mfinish \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;66;03m# Run hooks that need to happen before the last messages to the\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;66;03m# internal service, like Jupyter hooks.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/lib/telemetry.py:42\u001b[0m, in \u001b[0;36m_TelemetryObject.__exit__\u001b[0;34m(self, exctype, excinst, exctb)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run\u001b[38;5;241m.\u001b[39m_telemetry_callback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:783\u001b[0m, in \u001b[0;36mRun._telemetry_callback\u001b[0;34m(self, telem_obj)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_telemetry_obj\u001b[38;5;241m.\u001b[39mMergeFrom(telem_obj)\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_telemetry_obj_dirty \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_telemetry_flush()\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:796\u001b[0m, in \u001b[0;36mRun._telemetry_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m serialized \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_telemetry_obj_flushed:\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39m_publish_telemetry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_telemetry_obj)\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_telemetry_obj_flushed \u001b[38;5;241m=\u001b[39m serialized\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_telemetry_obj_dirty \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py:60\u001b[0m, in \u001b[0;36mInterfaceShared._publish_telemetry\u001b[0;34m(self, telem)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_telemetry\u001b[39m(\u001b[38;5;28mself\u001b[39m, telem: tpb\u001b[38;5;241m.\u001b[39mTelemetryRecord) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_record(telemetry\u001b[38;5;241m=\u001b[39mtelem)\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock_client\u001b[38;5;241m.\u001b[39msend_record_publish(record)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    172\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    173\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_server_request(server_req)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_message(msg)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sendall_with_error_handle(header \u001b[38;5;241m+\u001b[39m data)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msend(data)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f77d015b230>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f78e19e0f50, execution_count=2 error_before_exec=None error_in_exec=[Errno 32] Broken pipe info=<ExecutionInfo object at 7f78e19e17f0, raw_cell=\"import wandb\n",
      "device = 'cpu'\n",
      "\n",
      "def train_snn():   \n",
      " ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wyx/darwin_neuron/Workspace.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:547\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_pause()\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/interface/interface.py:769\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_pause(pause)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py:289\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock_client\u001b[38;5;241m.\u001b[39msend_record_publish(record)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    172\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    173\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_server_request(server_req)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_message(msg)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sendall_with_error_handle(header \u001b[38;5;241m+\u001b[39m data)\n",
      "File \u001b[0;32m~/miniconda3/envs/snn/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msend(data)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "device = 'cpu'\n",
    "\n",
    "def train_snn():   \n",
    "    run_name = 'sanity_check'\n",
    "    config = { # Dataset:\n",
    "              'nb_input' : 100,\n",
    "              'nb_output' : 10,  \n",
    "              'nb_steps' : 50,\n",
    "              'nb_data_samples': 1000,\n",
    "              # SNN:\n",
    "              'nb_hidden' : 10,\n",
    "              'learn_beta' : False,             \n",
    "              # Evolution Strategy:\n",
    "              'nb_model_samples' : 20, \n",
    "              'mirror' : True,\n",
    "              # Training: \n",
    "              'std' : 0.05,\n",
    "              'epochs' : 50, \n",
    "              'batch_size' : 256,\n",
    "              # Optimization:\n",
    "              'loss': 'cross-entropy',\n",
    "              'optimizer' : 'Adam',\n",
    "              'lr' : 0.01,\n",
    "              'regularization':'none'}\n",
    "    with torch.no_grad(), wandb.init(entity = 'DarwinNeuron', project = 'PPSO-Randman10', name=run_name, config=config) as run:  \n",
    "        # initialize Evolution Strategy instance\n",
    "        # es_model = ESModel(RandmanSNN, run.config.nb_input, run.config.nb_hidden, run.config.nb_output, 0.95, sample_size=run.config.nb_model_samples, param_std = run.config.std, Optimizer=optim.Adam, lr=run.config.lr, device=device, mirror=run.config.mirror)\n",
    "        es_model = PPSOModelWithPooling(\n",
    "            RandmanSNN,\n",
    "            run.config.nb_input, run.config.nb_hidden, run.config.nb_output, 0.95,\n",
    "            sample_size=run.config.nb_model_samples,\n",
    "            param_std=run.config.std,\n",
    "            lr=run.config.lr,\n",
    "            device=device,\n",
    "            mirror=run.config.mirror,\n",
    "            acc_threshold=0.90,\n",
    "            topk_ratio=0.25\n",
    "        )\n",
    "        # load dataset\n",
    "        train_loader, val_loader = read_randman10_dataset('data/randman_10_dataset.pt', batch_size=run.config.batch_size)\n",
    "        \n",
    "        # epochs\n",
    "        for epoch in range(run.config.epochs):\n",
    "            print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "            \n",
    "            # train the model\n",
    "            train_loop_snn(es_model, train_loader, val_loader, cross_entropy, device, run)\n",
    "    \n",
    "train_snn() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
