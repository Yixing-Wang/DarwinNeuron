{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import cross_entropy\n",
    "import wandb\n",
    "\n",
    "from src.RandmanFunctions import read_randman10_dataset\n",
    "from src.Models import RandmanSNN\n",
    "from src.EvolutionAlgorithms.EvolutionStrategy import ESModel\n",
    "from src.Training import train_loop_snn\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 78qhh6zn\n",
      "Sweep URL: https://wandb.ai/yixing/ES-Randman10/sweeps/78qhh6zn\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {        \n",
    "        # Dataset:\n",
    "        \"nb_input\": {\"value\": 100},\n",
    "        \"nb_output\": {\"value\": 10},\n",
    "        \"nb_steps\": {\"value\": 50},\n",
    "        \"nb_data_samples\": {\"value\": 1000},\n",
    "        # SNN:\n",
    "        \"nb_hidden\": {\"value\": 10},\n",
    "        \"learn_beta\": {\"value\": False},        \n",
    "        # Training:\n",
    "        \"std\": {\"values\": [0.05, 0.1]},\n",
    "        \"epochs\": {\"value\":50},\n",
    "        \"batch_size\": {\"values\": [64, 256]},\n",
    "        # Optimization:\n",
    "        \"loss_fn\": {\"value\": \"cross-entropy\"},\n",
    "        \"optimizer\": {\"value\": \"Adam\"},\n",
    "        \"lr\": {\"value\": 0.01},\n",
    "        \"regularization\": {\"value\": \"none\"},\n",
    "        # Evolution Strategy:\n",
    "        \"nb_model_samples\": {\"value\": 20},\n",
    "        \"mirror\": {\"value\": True},\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"ES-Randman10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§¹Sweep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_snn(config=None):\n",
    "    with torch.no_grad(), wandb.init(\n",
    "        config=config\n",
    "    ) as run:\n",
    "        config = wandb.config\n",
    "        # initialize Evolution Strategy instance\n",
    "        es_model = ESModel(\n",
    "            RandmanSNN,\n",
    "            config.nb_input,\n",
    "            config.nb_hidden,\n",
    "            config.nb_output,\n",
    "            0.95,\n",
    "            sample_size=config.nb_model_samples,\n",
    "            param_std=config.std,\n",
    "            Optimizer=optim.Adam,\n",
    "            lr=config.lr,\n",
    "            device=device,\n",
    "            mirror=config.mirror,\n",
    "        )\n",
    "\n",
    "        # load dataset\n",
    "        train_loader, val_loader = read_randman10_dataset(\n",
    "            \"data/randman_10_dataset.pt\", batch_size=config.batch_size\n",
    "        )\n",
    "\n",
    "        # epochs\n",
    "        for epoch in range(config.epochs):\n",
    "            print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "\n",
    "            # train the model\n",
    "            train_loop_snn(\n",
    "            es_model, train_loader, val_loader, cross_entropy, device, run\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sweep_id if picking up a sweep:\n",
    "# sweep_id = ryhbaq55\n",
    "wandb.agent(sweep_id, train_snn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Run (for old people)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "def train_snn():\n",
    "    run_name = \"sanity_check_1\"\n",
    "    config = {  # Dataset:\n",
    "        \"nb_input\": 100,\n",
    "        \"nb_output\": 10,\n",
    "        \"nb_steps\": 50,\n",
    "        \"nb_data_samples\": 1000,\n",
    "        # SNN:\n",
    "        \"nb_hidden\": 10,\n",
    "        \"learn_beta\": False,\n",
    "        # Evolution Strategy:\n",
    "        \"nb_model_samples\": 20,\n",
    "        \"mirror\": True,\n",
    "        # Training:\n",
    "        \"std\": 0.05,\n",
    "        \"epochs\": 50,\n",
    "        \"batch_size\": 256,\n",
    "        # Optimization:\n",
    "        \"loss\": \"cross-entropy\",\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"lr\": 0.01,\n",
    "        \"regularization\": \"none\",\n",
    "    }\n",
    "    with torch.no_grad(), wandb.init(\n",
    "        entity=\"DarwinNeuron\", project=\"ES-Randman10\", name=run_name, config=config\n",
    "    ) as run:\n",
    "        # initialize Evolution Strategy instance\n",
    "        es_model = ESModel(\n",
    "            RandmanSNN,\n",
    "            run.config.nb_input,\n",
    "            run.config.nb_hidden,\n",
    "            run.config.nb_output,\n",
    "            0.95,\n",
    "            sample_size=run.config.nb_model_samples,\n",
    "            param_std=run.config.std,\n",
    "            Optimizer=optim.Adam,\n",
    "            lr=run.config.lr,\n",
    "            device=device,\n",
    "            mirror=run.config.mirror,\n",
    "        )\n",
    "\n",
    "        # load dataset\n",
    "        train_loader, val_loader = read_randman10_dataset(\n",
    "            \"data/randman_10_dataset.pt\", batch_size=run.config.batch_size\n",
    "        )\n",
    "\n",
    "        # epochs\n",
    "        for epoch in range(run.config.epochs):\n",
    "            print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "\n",
    "            # train the model\n",
    "            train_loop_snn(\n",
    "                es_model, train_loader, val_loader, cross_entropy, device, run\n",
    "            )\n",
    "\n",
    "\n",
    "train_snn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
